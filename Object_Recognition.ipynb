{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 1-Object Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMCy_VwKJs3Q",
        "colab_type": "text"
      },
      "source": [
        "### **ASSIGNMENT-1: OBJECT RECOGNITION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-r0VnLFKTQG",
        "colab_type": "text"
      },
      "source": [
        "**IMPORTING REQUIRED LIBRARIES AND PACKAGES:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NOzsm0ap7d7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np                                                    #importing necessary libraries and packages\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Activation, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import regularizers, optimizers\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from datetime import datetime"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx41PQ9vKb6I",
        "colab_type": "text"
      },
      "source": [
        "**LOADING THE CIFAR10 DATASET:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STTgPSCTqz6t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "baec67ef-78dd-474e-f764-35e29e42da2f"
      },
      "source": [
        "from tensorflow.keras.datasets.cifar10 import load_data\n",
        "(x_train, y_train), (x_test, y_test) = load_data()      #loading the cifar10 training and testing datasets"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmZb5d9bwe8e",
        "colab_type": "text"
      },
      "source": [
        "VIEWING THE IMAGES AN THEIR LABELS PRESENT IN THE DATASET:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brfiFGBSwGFz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "adbc51be-ab1b-4b97-9eaa-aa8991aa39ed"
      },
      "source": [
        "num_rows, num_cols = 2, 5\n",
        "f, ax = plt.subplots(num_rows, num_cols, figsize=(12,7),\n",
        "                     gridspec_kw={'wspace':0.03, 'hspace':0.01}, \n",
        "                     squeeze=True)\n",
        "\n",
        "for r in range(num_rows):\n",
        "    for c in range(num_cols):\n",
        "      \n",
        "        image_index = r * 5 + c\n",
        "        ax[r,c].axis(\"off\")\n",
        "        ax[r,c].imshow( x_train[image_index])\n",
        "        ax[r,c].set_title('No. %d' % y_train[image_index])\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqsAAAFgCAYAAACc3DAbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9ebBlyV3f+ctz9/3tay2vqrqq1Htrl1o7AgSW2AyYMTYww4AnJhzgmBlmxmE7TAQzMTEeZrDDODAxbGGwWcYGCaENJEBrt5C61VtVd3VVdW2vlre/++6+nHNz/qgS1Pd7br9q0fVKt1XfT0RH9+8u5+TJk5kn3+1P/tJ5700IIYQQQohRJPhmF0AIIYQQQoiXQ5NVIYQQQggxsmiyKoQQQgghRhZNVoUQQgghxMiiyaoQQgghhBhZNFkVQgghhBAjiyarQgghhBBiZLlrJqvOuQvOuTXnXOGm137KOffZ23T8aefc7zrndpxz2865/3Q7jiv2nr1sG+46/9w5d8k5V3PO/b5zrvxqjyv2HrUL8XLs9fPkpmP+pnPOO+fuuZ3HFXvHHo8b8865jzrnrt5oF0uv9pivFe6ayeoNEmb2T/bo2H9kZitmdsDMZszs/96j84i9Ya/axo+b2Y+Z2TvMbMHMcmb2y3twHrE3qF2Il2MvnyfmnHunmR3Zq+OLPWWv2sbAzD5lZj+4B8ceae62yeovmtnPOefGhr3pnHvUOffVG7+OftU59+grOahz7jvNbL+Z/c/e+x3vfd97/9RtLLfYe/akbZjZ95jZb3jvl733DTP7V2b2I865/G0qt9hb1C7Ey7FXbcOcc0m7/sfLz9ymsoo7y560De/9qvf+V8zsq7ezsK8F7rbJ6hNm9lkz+zl+wzk3YWYfN7N/a2aTZvZLZvZx59zkKzju28zsRTP7D865zRuN7z23rdTiTrBXbcPMzNF/Z8zs6KsprLhjqF2Il2Mv28b/YGaf994/e3uKKu4we9k27krutsmqmdm/NLOfcc5N0+sfNLMz3vvf8d6H3vvfM7NTdv0XkFuxz8y+08z+0szmzOz/MbM/ds5N3cZyi71nL9rGp8zsp5xzS865ipn9rzde1y9orx3ULsTLcdvbhnNuv5n9dzeOLV677MW4cddy101WvfcnzOxjZvZP6a0FM7tIr100s8VXcNi2mV3w3v/GDQXg981s2a77aOI1wh61jd80s9+z639ln7Trf9CYmV3+WxdU3FHULsTLsUdt49+Y2S9473defQnFN4s9aht3LXfdZPUGP29mP23YOK6a2UH63AEzu/IKjvesmXl6jWPx2uC2tg3v/cB7//Pe+yXv/T67PjG58kq+K0YKtQvxctzu58n7zewXnXMrzrmVG6897pz70VddUnGnud1t467lrpyseu/PmtkfmNnP3vTyJ8zsmHPuR51zSefcj5jZfXb9L6Nb8WEzG3fO/YRzLuGc+yG7rgZ86XaXXewtt7ttOOcmnHNHbqQqus+u+0m/4L0f7EX5xd6gdiFejj14nhwzs4fN7JEb/5hd/1/EH759pRZ3gj1oG+acy9p1v93MLHMj/pbnrpys3uAXzOyv86B57zfN7ENm9j+Z2aaZ/S9m9iHv/YaZmXPupHPuHww7kPd+y8y+167L1Dt2/Wf/7/v6d8VrjtvWNsxsyq4PTk0z+6SZ/ab3/v/dw7KLvUPtQrwct/N5sua9X/n6Pzde3vDet/f0CsRecTvHDbPr2mHjxn+fuhF/y+O81/+tFkIIIYQQo8nd/MuqEEIIIYQYcTRZFUIIIYQQI4smq0IIIYQQYmTRZFUIIYQQQowsmqwKIYQQQoiRJbnbm+98z3shVUC1ugXvZwJMCTiRxswCByZx58DpiYIxU2NFiNOJFBYwk8MvJLDIW9tViHshlmF8rAJxEPUh7na7EHc6HYizuXgKs8giiFvtBsSVsTJ+wePne90exAnDa04kEhCXilhHhQLWYyoVL2ObzuEd/V0SYD1ymULvIP7H/9uvwgu/9tHPQEVfPvUkfH79/AsQRxGeb/bA6yA+cOReY8bnDkCczeExTp98DOKLZ3Eb7X4d70uCylAex7aRzGJ7fcs73g3xPcewzJ0d7A9mZidPPAXxYID12utj+3r+5HMQ16qY7azbw/bZ72Hb2NpsQdxo4fHDCL9vZjY9PQHx+AS2r8jX8RjYZazTxj72kT/6U2wstCHGYPAtmDqUkqg4h1XQbuJ9MTPb3MJ7OzExDnHUw3uXy2N7TKQzEHOfHhiWAVvKN4cgCP66UPsXClBruRyO7VyHyQCvIAjwesMBjqs3DgJhdacGcTZIQ1ygcbDexSxAQR7rPJeh79NYXKmMQby9jWNErxnvj5yPp9+jDke9K5HEekmnsF4qBXwezE9jO7uyugpxs4f1WC7j583Mwj6WstnEzbX2LeIzL5XCek0mMf7//uRpuKr//PHHdx0zchm8D+ksXuMgge+HPv47XJJ6RIKaT4qHKcqU5JN4zL6j9+nrQUSveHzOc51GwbD2HH8Ji+h3jfn7gwGdkz4Q29mIjjdsLI+iIeXe5ZhhrMx4zJ/83vuHXrV+WRVCCCGEECOLJqtCCCGEEGJk0WRVCCGEEEKMLLs6qyefPwlxdYOcK1Il3SS+MBWV8P3cTOwczQE6PQ3yPLxDR6jVQQew1SanL0L/YSOB+kM2iccPQ/x8ghymDLky18vQxGOQl+g6kxCTemV98mRzSay3BvmjW1EIcT6PnpQL0IUxM3Pk/hr5Xq0OelFhH+NEMn7dN1MjF2tyDD1IPz2LcRKdpvkDhyGOBuRpmVkwQO9v0MJ66Gxv4jna6PwtTmF7O7D/Hoj333MQ4oXFfRDPzOA1pFLkRY2hU2hmtn/fHH4mxHvZ6aATV91Gr3ZjA+s1meZOho1pfBLLlC3g8Xdq27EyZrLYxgce6zVF9762Q1549xvb9Y5dw7uBbmsn9trW5XMQL7+An9mp4bjyjm97P8TlmD+P9erIPxu1Wk+Rix+RDD2gsdulcezvhthO2d28/iWsg7ES9tEyOaa9Otb5oI39NZ9Cr7aSxzhP96SYxnF3g55PAx93VrNZ7G/T01MQb29jH+Z1FAvzOM4lyBKcmcGxOUXfP798FeJ0Kq4Mjo1hvRVp+clkBf1/bovNFtYzM6BTJjNYjz3yk5s76NWnCuRr030zMzNah8GOd0gOakTPyM4Ojq1pum+RYftt0FqWwOHniwWsM29xH3RAPih73bdyTOmSYs4q1wErr+yoDtvxlJ1VLuOASjl4BR7sMEZtPBNCCCGEEOKv0WRVCCGEEEKMLJqsCiGEEEKIkWVXZzWXJJGENMaD5KguzaKDMUP5HHP5eJ7VWH7CLnqHnT46Pp4+n6ZcfUZ5Vv0Av1+ZQIeJc52lyXUZlkKM8x12KT9iP8Qy5unzyQKeI0vvhw79noDykIWcT3FIVrJiAa+zQXkf++SLBXSMei3u3OEB8Pu9LsatFrpfS8cWqTx4jZx/1MxsYoryoFI+waNHj0H86NveBPHiLDqolco0xP0k3tw8OUhJTllHzly7iU6SmVmX6iWfw/swPoZ+2ZHD90H8wgsv0kk5LzDexwrlREyh5mc7NcypaGbmDe8Ne0zb23hv2i3qg9+YsjrUc3qtw9cUkBy2snw+9p1nH/88xP023stUEe9lm/pgeQLH05hvRnlXR6HWbx7f05Sn0lF5x6fQ9W9y/UToqIbUH83MHN2X+Tnsb3PTeI7zZ1+CeCqJY87cAjroQYhlDuh5xF7xZAXXbfhE3KWskO+Zp7E7EeB1Ts+i05olT5bH7tDjGFKh3OOL9MxMDJkVJFP4mQzlNR1wrtYSrlHw/d29xBqNpX0aRzfWcX3C5StrECey5NSW4rliMwHnKcb3e+xQ97HeW5S3O0drGIzyztd76NX2enjCw4eOQnzPEVxDYWaW43yy5HfGfE+6Jk8vDFhi5fBWeVtfATynC7gMQ9zcV4J+WRVCCCGEECOLJqtCCCGEEGJk0WRVCCGEEEKMLLs6q1mHzkaphB8/toheyGQOnaLUAD3Exha6cmZm0QDny23KpUlbOVt5DPcxT5LvWaX8a7QlsU1Q3r065TbsUQ7Vdiee/5M9kCLl7uv3aH9p2pM+RblbowjPkSQJtUs+aJrExGAQd7e6DcqvGbFzhG+H5L7sDNnDGj5P+UJdiM5SJo1u1g7l6J2cQ5/0wP2YA9XMbGb/AsQpFjLJMeqH2N5OXUPPqXVuHT8fYHt88blnIH7zveiTvvstb4Z4mM9TI1/s0kXOYYgOUjqNbtfUNLq9l5bP4Oez5CK3sb3WaljPySE5E8tlPEab3EBK6xvLRZyh/dFvBTtM3wpwTsQ+ucRXly/GvlPmHJ1j6DOubePYtXntCsSz+w/gASmBM7dGxyL6N5lKGa+X84XOzKBfuraJ/TdL4+bONub/NTObnUIvPUMDXS6HfufifnRSC7GxHDtD2rDtZ+j502rjuLh/Aa/JxzagN0tTf+r1cFyamiR3n9zIbhfHgBL37y6Wqb6Dz4ZuF8fuySm8T2ZmuQI+w5IOv5Ps4TV0mnjOsBt/jt7MY19+HOIGOayB4X1rU67nToRtJZXG2MwsQXONiLpHh/JNR+R3Fijndc5hnWSprUX0fGk2sQ6eePYpiNc28FlhZnb40CGIp6bQV87l8V57Wn/AOVAHtP7FUZ18wwsShuA5NyvnhlWeVSGEEEII8a2GJqtCCCGEEGJk0WRVCCGEEEKMLLs6q+MZfDtHzlCF8oVOl9EriWg/3yEpS+P7O9M+4l3aMz5JEmqSHIyI/ByfwOOtraHnFPWxVPUWumetKO7ZFnPoGRo5Pwny2TgHYyKD7ku7ia5lPoXHT5Lj0elgmdr9uLPK+/FWG3iOagvrtUGucKe/+98xXdrruUj+WXkC3bE3PPwIxPsPY465+pCciS+eW4a4RvemUcV7uVlFT+naCrpZZcqzagF6uR/7gz+EOPX3sA7e8/Z34vupuIc1N4eerXl0SKvkJX7tqWchTlLuvgLlKwzJPe41sA6ouds05To2M4uoTW9uYRkDQw+K+9wY5Wm8G7hVXtX1LWx7Fy5cih2jS58pZdHzazVqEJ96Bp22uaUjEI/Nod/MvhnrZ99sd3iK8qiyq9br4Bg1SzlS81l83mQS9Owws/lpyqXcxzFjcwPzc5bIo+VczoMeljFFuceDACu53cJ7yHkvg2y8zF1a49Dt4biUoeduo4ZjSKGI/ZU9xc0tHAczKfRyuVn0evH1CvUGO6T4pV4Nz9nr4djI6zqYaoOe25QE1dHzLEm5ZfPkjyaC+NSGfeMOzUhC+u2uTs+4NuUGzzi8l0WP94nz1aYy2H479Ex+aRkddTOzi9dWIB4r49i7fx+u/ZimPjY2juuKkuS5J2j+dKu8qtGQt2P5nmPjEOWGjTmrr8yT1S+rQgghhBBiZNFkVQghhBBCjCyarAohhBBCiJFlV2d1egw9xFIKfYcs+TdBAt2DXA4djX4Yt1bjvgP6dD3atzgiF2ZA+x578vF8Ej2Veg+9k4j2m25F6FeEUTwHWJ3ypV3ZwmOmKA9euYHX2F9BR7C9g17VgSnMOTozg16KK2Euz+52PKdco4Fl2qmjH7Oxg47QhWU8ZjRsg+ibyGTQGeon0P1q5zAf7vkanu/pL34F4q1NdKLMzK5cxX3tU5R/luu5G+K9Z7d3fhqvaW0Fc2GWKd9hvYr+2enzuN/7/DzmvDMzS6XwHPOUx3GB4ksr6OW++BzGM/Po4F24hG3HaM9tduyiZLzPZSk3ZCZJOQw7tM93mRzqJO2JfVfAHhbW0ZXLlyE+fwljM7Pls+cgniphH9k3hV7ftUvYPp974qsQv+m9YxDnyWdjX/KbTUAuf6+LY1JErmTI/buD42SSBW0zq1W3IHbkJXryOa9cuwZxpYjjWJ6eH7UujpPs56Wz2P/7nAt6iA/qaJ3GgJ6TgwTnsMb+ygl2W208RzqDTmuavPh8FhvKsDzKO7Q+YKeK9VDMYttz5BPH2ibRZjc4xc8fmidQbnJvGLtEfNwjzdx6fWx/fTplKY/9s17D9ldj15gc7HQa67GUprUrCXy/GcbbBueG7W5gvVer+NwsFHHONT+PayiOHDoMcZGfBVTmfp/a75CUqN7wXnMu17jDit8f5sEOQ7+sCiGEEEKIkUWTVSGEEEIIMbJosiqEEEIIIUYWTVaFEEIIIcTIsusqmoVpFP7LaUzcXsyjjOs8J0n39H7czu22UVrmZMOTJRSzCwVc9FXbwQUnFVoMUu9gmS5ewc83uigHp6mIi/l4FSVTtDhpE+XzrsdjpsjsrlAi6kfvexPEtWu0KKBF359Cwb7bipex0cC/QzIp/M7+OSzDzMwsxKs1lM+ZfB4/v1bFtnF2GRcKPX/yBMQBCfRRN55gv13HRWIJWnDR7uICqGod43oT5fMLl1+AuJDDOjh+5DgWgBZsfekLn4X44KFDsTIfO34M4slJbL8ZWoBRKaPgHoQo0De7eB/bLZTw21VMEB5FeN+yOVqMYfGk4mXaeCBDCyc5wXeLNme4Ndzvb7Xy52+xMshzyC9QGRwnHb/V3+34+cEA2zsvpKm34v3n8iou/lmlOIowCf6+GSzTqa/iosSZuXmIj735LXRGbGsBJ1oftrCBqoG+MnQM3xX3NwfkxO7pNJaPF2KEtIim28FxdzwXTzSfCrDAyQDbf6dH4z1t0NLr0gLfGo5BaVrAwotoHC1CjmjRTI42NjAz61P/KpVx4Vw2i2V0jjayoYT9/R6+72hBFR/PaBFNtxVf6BP1sGGkk7j4qDyBm4/0aaOaWnP3MaNNi+26tCkNb2jB18BNmdutmdmAGjzHTXpeZHO08IzvbR/f79CGRKGjhUZ0vnTAGyLFy8xXlqRNlPiY9RZew84ZfOZtbOL8p0QL4/Yt4mLucdpUIJ2Jt9/Y2Egb/IQ0ZPDmC5Eftl1UHP2yKoQQQgghRhZNVoUQQgghxMiiyaoQQgghhBhZdnVWJ0roJyR76GZmyDvMU/LhbpsTyqLLYGY2NoZOBHtLvQjn031K5JsvojtzdR19m5cuogO4XscytKhIB3PohHz/ux6JlXnfPJ7zvzyJyb4fP7sCcThADyoZkGdSXccyNfAaSiXyDiP2d+JeYpq8w7zDz4QRXviB/Zg8uLSFXiMzNoEJ8c8un4b42gVMoJ9P4TXtNLchbtTWYudwlGS5Wkcfp9rGtpCkjQqmZtEBzJH/vLj0MMT7qc7OP/M4xAmH97EfxV2b9Q3coOHBB++F+J6jmJR5PyX9L77t9RA/e+oSxN0OulrdFG0KYOifDny8z62sXIU4nUGnrTKO9WaG3l673bZvjFeY9fmvP/0KnNWYpMaJpyk2rIeYoxpzWDlm8JUDS0sQ58kDNjOrNaneHJbhxDL2gRxtvpCkTS5OPvY5iCcX0SMf34dtzYW8hiB+VVz3Axqrgm/sVkK1BpT83g9oE5kCPm865PylC+ioRs24W2kOn0lzs1gn4SZdAHnpBUqS3qUxpzKHbuat/O2pWezf3UYv9pkEjc0pdkzJE+y0sUyZNL4fpPH5tEP11O/juJWgZ0GnE18/YAMcG3PkjCbJ3e308TrXN/AZx/TIhXa0Gc+AngWD4BZjRGZI26ZNJAYBXneSZkN9SvqfTuI1F3N4za0ePo9CGnO61PS61B8zQXw6lqCE+57GLZ5ThbQJBve5lS0cY6528Xl19iI+b6an8Tm/sLA/VsYibaSRJQ/ck5vb9+SsDnmODkO/rAohhBBCiJFFk1UhhBBCCDGyaLIqhBBCCCFGll2d1ZmJSYjbW+hkBOQHNVrourR75IQ4yitmZi3yZ3j23Cb3ZWwcXbBehN7Hucvo423VKGdpEj2TBHks5Sx+fiYZdzezW+gAHS3PQXxtAo+5WkVPpNvCa3rqNPqeASUm6xfIf6ugh2VDXJdKBf3hEvlhHcrt53uYo3RpOp7D8GZeeglzPp566SzEV6+9BHFEOVNLFTz+8aNLsXM8cO8DEF9bR4fo4joec3oO6+XgEcyDWppEF3N1G7/vN9CzvUT+znoV/Z5774sV2b7jGDqqzQaWeUB6ju+Rh/hl9GSPHkdnenYRczB++Sufh3hlFe8j5zs0M+u08Zzb29jGc0U8x4B8smYL6+3WfGN/Ew/N/0mwk2rUvgeUu69PbmIsP2bspOi8xYpEY9n4OLpd73z3e/kb9tzTpyC+cP4ixFGIZT6bQPc9u4ReefTiGTz+574E8Vu/B33JXB5dxmiI9uc4ryq9H97CP2bX9+aR6co6rh/ge1joYjsr0hjRofyhxQTlCzWzxXlcA5HJY3kSqMrbOOUKH8vjMUtzeF+7JO2eJv97bAzH6i65+R1eJGFmKbqOfo0c0i4+bwbU9hKU/7PRwP4ckirNz8zpMXxWTJSxDs3MztRxXcYk5d/kR3uZ/ONBH71GJrxF/t6I3MwOXWOShNNhbTsZ4BjAynYqxW2XnqsDztWM9VhM07oQGvYGFPfpeGEU95kD8to9zQ0iclSjBPVPft7Q247XsvTx+LWr2H4vXrsQK2Mmje03n8f2xDlxMzT2plK85uah2DnM9MuqEEIIIYQYYTRZFUIIIYQQI4smq0IIIYQQYmTZ1Vkdn0LnaZz2RQ5o3+VqDf2GPu21GwzJpzWgfcM95W4tFsnnMYxfOIe+Z7OLPl02SznraD/qXAH9ivEEujFPnl2NlTns4TG6FXRWp8dpL2fKfdkP0f1tUT63ZotyzdJeu4483mFpKXmPbM51liLHJyQvyke7u2lf/vynIU7OHof4yL0PQpzr4X2+976jEB8/hnsSm5lFHcoxF1A9Ge5znExhvScS6F72Q2wLzTruzV4hxzqkOri0hu07W7wSK3OFfK/DR5Yg5jx57SrmaTz1V0/j59tYbw984LsgfvAhzKXZfgKd1ZfOXoiVMU/uYmVskj6B/bRG/brb3T23ZIzYBvO3+jznSI23xZhLSflkz5xFn7PdxnHhdfeiW5zJYFsLWN4kBh4/P6Ch9NF3vCv2nUvnsb38+q/+OsQhucSX1imvdR7b71Fy41/8whMQT1Oe1de94y0Qt2yIP0liXZrqYauF3mm3h+MGe7eHZv/GG++Sb7e1hf0v38JxcYLGuRTVcbYY9+o7LWz/DXZE6bYmaGzt1vF6pkvYV148g157MYvPj2IOn5Fd2i9+fB7ztJqZuYi8wRaWIUtP6XoH6zhDeS1XVtGjtQGWqVjBcbHTxv4c9uN5VnOUg7pUQO9wi/LRdrp4L0uUD53p0r121O4Gg93zKIdUz+0hY1SKnNIE+aCZJL7vKc+v4z5PzqmnBQlUZGtRPtsezX2CIL6mp0f1kPL8XKf1LQGt0aEyBAk6h6N1SPTzJY+8AxZvzaxHeX9rTZrnsYvbxc/zvTb7sdg5zPTLqhBCCCGEGGE0WRVCCCGEECOLJqtCCCGEEGJk2dVZNXJSXSwfFpKhPerzhk5RcsjcmPeu7ZPHkcnhfu4bK5hfrbWBPt3hCdo7HZUMy5KjevzIIpaHvhAm4tfMDl8ygR5XKY3XPTl+BOIjRw9AfP7SVyE+dRrdtnSSfFKPzkcYxm9jQPlk2deJ7bXMe6G73f+OWVtGX/T1D38Q4kwGfecJUmXmF9Dj3arG89kun0WnrTdAZy9wtMd1knLQedo7nOopIs/JR5znEXMsbjbQewzScWduwJIQWz+Uqq+YxXpYor2Xs5Q3LzC89w8+gLlkx8bQR/to+89iZVy5hu13cYbyd5LHlCKPvFZDL/BWcJ1wSlP2zzy5XUObInlOy1cwJ+6ffOJjENdq2Ecf3cDcx+97z7dBnMlgW+Nr4KyQIbedUjyv5Ie+70MQn30RffvPfBI98BrlyD11BfOujjt0EbMdrKgvfwrvfXISvcFgFtuKmVmzivWUIg/vWu0yxDt1/Hyng23n0N/5R3/93zMTWCdhB9tyqYh17ik3biKJ15ejvdnN4o5eizzgHiW/zJAQeu/xeyBeWcE1C13a4H1qGse5MELfc2D0TBzi2fZa2HYSOcoNSx5icwvrfIc84koZx5QGrYGIBljGDD3X+2HcZV48gOMSPy+2a3gv+fkyNoH1xLSo3SRZnhzsnvO03cT7lE7HPfeJWVwXkSO1MqBxJ0HtywdYbzvbmHe73cBx8eAhXMdR7+O9397G+5bJ4NzEzKzPLq+xF0vXSbeO3+elKGnDawpozU7Yx/scDXFWeYD2tG5oUF2GePMK5uw1/8p+M9Uvq0IIIYQQYmTRZFUIIYQQQowsmqwKIYQQQoiRZVdntd1Bn8H1aZNhEiSaTXQ2en2cC4dBfC/nRgtdxRrFi/uxiD7E9w9OoVNxZAH9m1YH31889jDEaY+uzPYOXnMuloPSzDZRwNw/Nw9xtYnOxuHXYU7R8nieYsz5uL2O17i9Qx4ZuZKBR9fLzKzPOd9IsovIh6O0rPG914l8EfMFpujj1So6gZkJ9ONalHORlCUzM8uNo+OWGVAhKd+gp9bc6WOuvWwOPxA49IEGAeX4nUSXM+3RoU3k4nto+zTl4nNYBhfRvUvgOVOUvzBXxDjsYtvYvIKu1mQB3bDv+zsfiJXxiWcuQNwgr6/TXYe428Z+P1aKu467Q3IYOU7b5H7tbGM9u0Q85+nKOravx5/4CsRPnnwG4toW5izlvI73P/gAxDPT6Csn6D7V6nhfq1U8/tK+eN7ghX0zEP/XP/0PIV6+8hLEf/XMs1jmJratM5fRYc3P4fubJ05A3PojLM+Rd7whVsZt2nO9RXlLuw6vs9enfes5ueRNFCmX7b1H0N3P0Z7i3DdWlq9BHIbkpJtZoYh1XG3gwJJw2J8cuZf1Hbz+9TV08+MpSPF502iQu+nxC60WPhvMzBo1LGM5j+Nej7xC78itJL+zTL50Lo/1mExSztQS5aceku+THdTzl9BDdLRGIk35POutIQP8TUTsyVIzGs+gn12mtSdtukajsd3MLNXAcSxL/vLMDLadTg7rpRfS3IBy7CbyWMY8ucNjBZwnzE1x32ET3qxDz+EWfWZlHcf/fhP7Z4raX5JyvCcGWE/9Prb/ZAKvcWDxORw/N61Nc7qrFyDubmOZG414P1rHvlQAACAASURBVB6GflkVQgghhBAjiyarQgghhBBiZNFkVQghhBBCjCy7OqsR5bHk/IfsNeaytAdxCX2Hq+vsvJqdv4x+XJLkxzTtc9xZxc8fnUFn6P3vRT/0pSvov5UW0embmpyDeI0ckLGxeF68YIDnTJPjs7aOeVKTWfRI1qvoXl25hp5TKoX1NlamnHJtykuZjP/N4QLeWxnvJe997sh74nxszPwBzO/J3+900HVbrWFTS4+hE9gP4zkTOa9vm3ywPuVnSybR3Q0TGLNDNDOJ98VvYfvskdfrBpznEdu7mRnrXgPasz6K6D6k8As+gedoNNH/ceQsZajea9R+c/n4XuTvfvtDEL/40kWITzyPLmSjhp5dOhX3lhB2sdhZxXCnhl7gFx77IsQXr2JuTzOzjRreu22qp4Dc32wX+/HaJp/zCxAvLWFeSc67eoXGrX4P3a92C8tnZtaok09Go++9bz4M8dNnn4O4V8dOebmKfSyfxjLuq+B9Ov/E1yBOZIbkvV7A9rITopsbsxk91nO3+/L+WZF87kIe7wnngq6MYVko/ahtb6LrbGZ28gXMXRtSn82kMdfsRAG986tXcOze3MB20gmxTmvkuMZyTpKGWK1ijmMzM9KnrdfFF/J5rLeJScw9zjmxuyE9t8kjbncovzT113BInlW+rxH16Vw+/py8mWQqPr7jSfGaK+TtjpGTeuUa5lVuU9vvRvFrcCs4zh2aREd1Zj/mXD91FecentZM5JtYj5UCto3nltGbL87hOFrMYHs/f/r5WJkjap9jR3HsLi5gXuDmxRcgTlDu1zLlaG81cExq1XEtQDqF/aXWifvMuTGcU01SR22Qc83jP88dXg79siqEEEIIIUYWTVaFEEIIIcTIosmqEEIIIYQYWXZ1VsfG0FcIk+iBNCiHne+jx8L7Rl+8hD7d9WOgQ5HL4vz52nl0Lmaz6L4sLh7EMi+gS5mqkzSURU9k38NvwbdX0FnKheimmZlFhtfdbGI8n0eHo0f7hrsC1uu+AubzLI2hR1vfRIdwbRVdrb7DazIz6/TIHQvQWypkKIdcm7zZdPyYN+Mduit98jtbdXS5MuR31mvoEvc6cdetVcNjpMh1KRXQU5oeR8etPIEe1fQYliFKovvVzuA1bB3E+9KN0DU2yuNqZhaRezUgzykKqC2Qszo2gY7SIMJzcH7cSgWvKe3wPlfrcXfS9/FeP3IvtrexEtbrxz6Ge8yvr6LHx5x8AV2tZJL2Hie/c5tylFYbOG5cuoZ90sysMoP5jyeoHiansA+uv4T37oUT6IN++jOfxuOX8XgJyk3Z7WE997o4BnzqT+N5JVP00wDnXc1PYT09/MjrIH7qiy9C3DJsS6c3yVemnL7jIXqAZ7/8ZKyM1WkcF7aovaZ6+H7I/b5FfeK//5v/3DeH18ve4/gYtv0EjTGpKXx/bjqeA/vP//JzEA8G1L9K2B9XruF9mh3H6xur4FhdXUNPcWMNx+axcfTiC+ROV+h9M7NSAcetUgXHpUIR20VIeY/PnUUXM0E5T1vkwPao//W6eB8SiSFrIKit5bI4RkT0DOpTQtp+d/c8q0GEn58rYr2vbqNL2af7mKTcsoGLu5VhH33hg2+4H+JtusYe5UNPOMrTXca2UqXnVZ3c4AF57N0OjeXl+FqAZZofNdfx2X9wDHNeLxxHp7X6PM1VrmBb2V7FuNbE40eUi3anHc95nRvHsba0H+OQcjV32visD4bk9R2GflkVQgghhBAjiyarQgghhBBiZNFkVQghhBBCjCy7Oqv1KvoLyR47hDTXJfUgSfsDt8hFMzMbL6FXNUa5ytrb6DvMLKCntPjQeyA+cRl9nNNnMX50Hv2gahXfnz3yMMSBxb3EHu2dPkbJ9GprWG+5Hvo48xNUhgj9n9RD6Ga1KS/rlz7xUYgvL8e92kTMOUXXhFK1Wp/+bgnim2Aj5GYmaY9hSvFo+yt4/tcdRtemmI3nLE1Q+2pSbs1OC9tTroBlPn4U63n/QdyvPUih79wgd3L/PO7lfPw8elPlibhjNEFOWpL8Md463VOfydKe1yF5TaQeW4rz21LOxMkpdL/MzBrkFTar6N0tTqNz9P3f850Qf+Tjn4kd82Ye+8pjELcpT2shi33+Qx/6PohDj/3hyedOxc5RKVEfGaCbtTAzC3F/Ff2xnSbWQesM+qDjlIO0UMEyF8nTyhZwDKiMxT2sCuX5LZfx3uSKeO/f+21vxTJvYHs/ceIcxFEf+9ilKtZJivIWJ1fiuSjr2/haWMJ+GeQwP/KVZRybanSvb8bTOJmhMYpdyX4Tj5VJ4PV5ltjNLKK8qkGA54j9OjPAMePgQVzzMEV9YR/lxM5QrswytZMElXltLe5fP/pWXDcxt4CufOjxPtY2cbzf3kAXc7OK9ZZM4KAxPYVO7IAGpQHlgjYzq5BDuk35ZT3l9e61sczs2jMTZXROp4oYV7fQx56gtScZagvsUpuZzRw5DvHhecylfPIS9qexDI7dISXEnZnDZ1hAY22T8p8HJTze9jqOuwdn8PlkZtZKk98f4b3d2sa2EMwfgHjffW+D+MplHEs7bRwHU9zHKOF6YhCfF3Sr+FxcN2wbIT1vAurnQ5rbUPTLqhBCCCGEGFk0WRVCCCGEECOLJqtCCCGEEGJk2dVZJX3BIsrF6cmDDIz2QadcZ9tDNMhajfa5p5xw8+QAvfl974N433F0Mv7ot34T4jnKaZroobt25dxL+PnD90GcncS9d83MCh6djNYWOhu5Afp0PfJCNuoYj02jJzU5twRxu4GuW0Cp+qJ0PIedI4eoT76No/2jncc4DHdtGvaet78R4sP3oevLe2wv0p7jx44egXhuGnMwmpklPF5DnXKGdinPKV9zsUCeYREd00QafbwUebftJvpAb3gAHdelY0uxMvfJ6fH092A4wD7iqZMlaMP4fod8MnKxAvKiXJY6bTL+92iXfORkAv2vqIf1PE0u1jvf9ebYMW/m3AV0v3bW0Kk7eugoxLkc3qerV7E/XTyP+4CbmRULeO9ibaGG/bxdJYeN2so9Rw5DfGQavb4Suchra+iPjk9gPc/vj++VXq9hGdOcAppygpapDN/xXTj2bZHPv3oZ622jiyfI75D/X47n/ExSnt7FEvbbwizm5L1y4QLEvRaOjTdzafkyxNw/63X08dgZ7NEe41Eyngs6T/k2e2287zPTODZnAmwnRw7j/vAZKkOQorzG5KzmcuTIUjvz7Xj9dGv4XO1XsEyT89gOghDfP7gfXcdMFu9zrYn9OZ3GMSZJ+UPDIesVOM9wRM/pBHnoPkR3vki5ZJmDc/j+3/3ub4P44rkliOsdrLNuB8sTduPO6tIC+pyeXF0/hW17h56ZzRaec98UPrNCcrIblH/dU27aoqe8woO4vDlL+aOba/hMalzBMaVPfb4wi21j4f53QTzo4zi2dhXnQ60GtdchZSwXsG0kDdunp6lEv4XH4Hnky6FfVoUQQgghxMiiyaoQQgghhBhZNFkVQgghhBAjy65iIulLFpHL4ijHI+txvk2fJ0fLzGxiEnMLzuXRNXnDm45BfO+j6Khur1HeuxAdjMP70NkYUCHmZmgfW8pr2aI8rGZmvRA/029jNUaGjt9LV9DVeu7EExA/+jY8x+Qc5pKt1dFFS2GV2dRS3I8b0L2JeuSkknO0s04+aJ1OQrzxIdy3/P7Xo7PafgCd1EIF/ThuCt7FvZWAXMqJAjpFntob/+U1GOBZYrn3qD13u+Sv3YOOUy6N9dxuxvMG+4C6FPlgnjrVwGMcUT1wDsQe7QseDbBMQZI98vjfo/VN9Jwunl+G+B3vfD3ErT56S3n2YonmDtZLi/bIzuTRHd6p4+cvLl+AeKwSdysj8sFcBx25aytnMb66gZ8P8PN/7wf/LsSDxhbEf/HFz2IZn0Une7KCbuPKmXgdLZIzt9PH3JGWwn4+MYm5Yh88/gDEve/HtvWbv/E7ELfrWEdXqzhWGuUANjPr9si728Cc0Qt0L9LkaE7NYO7Jm2nRnuADctV65NFPTKPHOCDfu9OJu5X792PuzOdPYP7cFPWP+Tkc/6fJaU3Q84JS1Vo6g/cgT22b86xaG8cwM7N2DR3TrXVsBz7A+5ij/sfnLJdwzKi1sC37COstRzmu3ZB2wWseyjl8PkRUr+U8HiN1i+3fywm8xre/AfvKW+5Hl7jewrbUp4dBP6TJi5mFLfLYacw41MNztLrYHhtN/H6K1hds033MHsI6aHfxfH6MchavYM5iM7Mz5OvfN46e7KV1vLdG3nuURYe7ePANEL/ryBLEW8vorL74tSchXlvB/mRmVnC4JsG66J53IiyTo+dy8laN4wb6ZVUIIYQQQowsmqwKIYQQQoiRRZNVIYQQQggxsmiyKoQQQgghRpZdF1gNSHhvU8LZNCXcT1KS5kSAUvY9cyivm5llczhfXjqIgvzD78RE2PPHH4L46cd/C+ID+/Ecc/c/iGWexoU/yTwmXG5RsuF2LZ7EefUqLkjZXsUFVBElKM+VUICfmsJ6Wr76FMSz8yh6h5SM2NNCBdckwdnMIk+JeWlhT46SWafnMK5ldl9Ek+OE+5TwuJCnpkVJpWndkLlhC6x4sRElXR70KabFSrwAMKRlXZSv27zDzxfHcIFHGOH3o8EQMXxAScAN+xAnCbcIY0507o0qKqTNHShJc4bKlIrif48WOvgZv4ptZf0cLvzZdxwXKW4EtFCH6NFCtRYJ92fP4+KnD3/kDyH+4uc+B7Hz8baxSonU1y9in0zRCr4+1VN6Dvv9lz7/BYi7NVyQ9fyZ0xA3V3GxT3Udjz82iX3ezGx9Bb9T28F6GR/DhS69CM/52c9+DeJcGRdijlOS8o0+Lo5qUaL0K/X4ZiKe+n2eypigxT9jk1iPicTLP1J4wSQncs/Qwp5uD8e5TBbbctCPr9iNaNOX+jYuHG01cBHMoQP4PMjR9RfzuEClMo73qB/SRgURJctPYJmnpvB4ZmZra1jma7Ro5skTz0J8Dy38XFvHa7p6DRPHh4b1OFbGMqRoXMxk4m03pPG728G2Q8Oe5SdwoV2tsfuY0djCZ9jl8ycg3reIG+cszuPiwyTdp4GLt8PaBvbpahXPOTmB/alJC8RbbdokoIF9o97AvnCcNhppNmnhES2Wnc7hM9TMLNXFMrzxrY9CvNXC9y+s4GLVXoD3MmpTnx/HBYYLD2E9Tz/0HRCH27Qo1My2XvgriM+f+CrEGy/hOBaksR6C5JCV90PQL6tCCCGEEGJk0WRVCCGEEEKMLJqsCiGEEEKIkWVXZzVF/tF2HV3MqIOiSi6PPk8iQN9uZjKeaH75GjpFR97wXRDvexBjM3RS+3X0Hyol9Eamjz0CcTOJHuLJp9Cv6LbxeLUals/MbOMKJupNkKeUzWK9LR5CB/WhY/dAHCbQ/0wl0PdJpdFLSZIv1LqICcrN4r5xSH+WNBLoIOUnsQyzC+jvMKUK1qMnH61Fmw54Sojc7e7u/5iZ9SgRdZf8nTBE16VPSf45kXWrhe231UQfOaRkxaUJbEulCt6XsRImdTYzy6bRu4sGtKmEQ28wMIxL5DdvruH3O210vwYD7A/O8PyDCOvdzKxcQjfq4AH0v9otvBeekrFXSvFNKOB9qrc+tb0aeYPPP/00xKvnz0McDBmm8uT2pgO8bt/DegsoAf0+8sInSliP25RA/PDScYgvRui7VbfQD40y8eT4q7SRQauFfbS6hT6Yoz7aoeTb1RYm8A7SOP4OElQnaTxeK7Y1h1lEfapAxyxWKGk+OZkDj9d0M3NTmBA/k8Lv5jNY3lwe71lI42yKxXczK2exrR5ZxLY9Rs+oBdrEoJjBOioXsD92Avx+eoBlru3g+bMF/HwqT7sKmNnKOvbp5S0cp148i+1iZQ3bUW0Hv9/vY3zfvfMQF7NYhogS7HNieTMzT+sBsmk6Bj1vHM0dwog2ZCHGcjim1DdXIL5GY/PUHLaNCp2vUBqyOUUFvdaEw+dFCW+VVYr4eU9jTEjPlxeePwXx9DT6oPk8usYteuY9vIRjkpnZe96ESfzbtNlBi6r16H68D6ubOI5dXUEfeoU2hLkU4fE75ALnxnD9gpnZ2AM4R3vk+NshXjyPzvWzj30C4vUVHO9fDv2yKoQQQgghRhZNVoUQQgghxMiiyaoQQgghhBhZdnVWu5STK5/Bj7ss5XQMUKDw5KnkinEX5nt/5HshfvS73w9xeQqdo9VzL0CcoHNW65hnbP3CixBfraPT8dmPfATiYg5dnE43nh9ubhadvDI5fOcvowfSozJOLCxBfOzBN+IJInQKt6qYx7VFrvB2O+4DOY/3qtNG56dBDpJv4L2+d4jyczMf+egnIY5SmKdym/KxNXYwxx3pzDGH1cxsdRWPEZGjNjGNeSXHp9CzzZDH1NxC//j0GWxLnAtw/6GDECdS2DbKpbjXe+gQekn79qOnd+gwuZKU17FEPtmgUsYTkMfYpz6WSOLfn4kh+XJnl9C1zZaxvfXJOyT10SYmqExEkZzVJPWP3ia6Whunsb/sL+L3HbliZmZ1Gps61MdcDl3DjMN6W1+lXJZ/9QzEsyV0tTYpX+cO5UhskP7Z3kAv90apIEpSxeZS5IuRd7texTJEAXnnSZTuOM9wkOXxd0h+Q48eX7OJ11mrYTw+SQMFJ9y8+dBUnmwO1zCkqO2mMhh36uhW9vtxP7ZSwrb5yCPY1rmOUym8B8kkO+dURwG2u0wax5hikVxq6n9+EH/kpqhenj+Fz6wm5dK0CPsPu/xpWj8QBNi/PeevDrAea9S2zczqLbxubru9Hva/sIuf73Xj7vzNzNOY4Xp4TVurmN/3mWcxV/NTJ7DOZhcxX7uZ2bve826IF6fxnJ1tdIUT1J8s4LaC9/LAAvrcORrLM2m8z+U0reEpxce5foTHrFPu1zbl6X7hzAWIt7uYc/cNh9GjbczgNZy/hq7wCxfRw33mHNa7mVmd/PypMl7XfbP4zHvTuzF361OPfzp2zGHol1UhhBBCCDGyaLIqhBBCCCFGFk1WhRBCCCHEyLKrszrw5BHS/tqOcvKF5Ds52o8+m4m7bo+8EX3NDHmBzz/9FMTbVzG3YJfcmPo2umjLZ5+HuOEp712E3y/SHsjlbDyn5PQ4ui7XVtHzCCnfZ6tOefTOY55Ws5NYxgbm/8wmsR7DDLqam2G8XnPk7OUpiVwuiR5TvYWOXTjYPS/ep//yMYjH9mEeSh/hNT/12F9CfHAf5mubmoz7n1cuU71S++P9p3sBtsdVcoff/xbM//bIQ/dD3KK2FKTI57l0EeLTZ7Atmpk9dwLb61ilCPEP/tAPQPyO+49BnPb49+O+eXSveuSsuoD8M3KR+xb3+oIkvpYZw7aSI4dukKD8lrEjIgNyszx5VWnKzZki9/BAGXP4hkHcda+TV5coYz0Habym9iq67N0q+mn1TexzGwMsY7WLn196w0MQr6xjntXqNp7PzKxYxLGkQ/ls+ynK6dnFPtjuY/sO6N5n6Zo95ZGMyFFNJOPDf0B5HAfkbK6tozdL6TUtmX55Z7XXx+upN7FOgxK6bu0q3pN+iNeTz6FXbGaWIK+wukn3nZzVnQa2I3YEPd2DVBKvL0Vts8V5jal+eu24u8lrQVZWrmGZPd7XboIcVfJsE+Qmcz7fkFzoDOWG3unEndWVTczx6436pMd6cQ7PmcvsOtWwZynfud/EsbYyia7lkyfRpTxFruY73odrX8zM/uN/+h2Iv+f974R4PEvzFWpfyRS1zw623+lJfC4PMtjft2/h7bpE/LfDPv2e6GiMOHsR17P861/61xBvrOF86K1vw2v+0A//GMQzc1jPhRDbwkIY798nqzhGDGj9wBo9N49SXu/Dx++LHXMY+mVVCCGEEEKMLJqsCiGEEEKIkUWTVSGEEEIIMbLsLpKQ4zQI0XVhh4P3B+7RvueztK+0mdmffvRjEE/Mor85w85eCx2kVArdy2IB/c0kOUUFcmLnZtCVbNfRzckl8PhmZpvrmDO038PrLmXRD+1R/s4zTz0B8bVTpyHukidiKbwGzq9Y2Ddkr/YC7Y2eQR8zS07quGGZ773/UPyYN/HDf//HIc7MHIW4VUff9MxzmMdyfg7vaxDE/27KZfFe9gZYL8cewHOOz6Mz1JrC9vah7/52iNnjbZKzyikjQ4/9oRPi583M1sgRunj+Kp4zj9e0chldxwsnz0AcdPAc51Yw3+BbvvNNEB9cWoCY87CamQVZyueXIhedfWXyz9JuSH7Om6iSa9htYVss9LD9Ts9hmTcv4jWevYDOk5nZeh/rZWICPdeA+mBzgP066tO+87Q/eqdLnh/59+srOAY0G+iv+X583/p8BsfLHuWKdRkca8IOlildwH7uI2qPlKt4QMmMezR+Z1LxvI7pLI2neXSBcxT36TqH9eOvs0G5ahdo7GWHNRzQPZ7Ee1yv4efNzMIQX+uSn0mpmu3UWdyXPKC2zX71AepfQRHrq9PEdhPR+cNe3AfN0DnYdz59Bdv/oel5iCdKlNeY8iA3m+i4bod4/CTliuUcxmZm2/TagNx6R1OJlMMxpNna3ddcJ4f8VArzgybWcJy8dA293ne//70Q/7N/8c9j5/jlf/crEH/8Tz4K8esWsT2m0vScpRy+UYT3eqKC7XN6At1MzsuaJlc4cPHpWIPG7x7lIv73v/pbED9/6jmIuY9/+KP/GeJ9xx+E+MGjuIYil0FHtuzjz5MFHBIspDI2ac2C72FbOLiIuclfDv2yKoQQQgghRhZNVoUQQgghxMiiyaoQQgghhBhZds+zStJemnKQZpO8bzK5CQl0rAa036+Z2cYGuo2NdYxzfcz/OaD8bhPj6JmMLWCesJDy3l25isf3xs4VVkkvjDsaCYfeayGLLhqln7UEv0D+W9RDhyigeq+10LfrZdB7Ki3EfaBmDv2w+gDdqU4T/06ZLB+GeGomnvf0Znif49OnTkBc26F65vyf5HI1Gphz0szM0R7W2QzWe7+FbuTOOp5j9RLmWf3kn34S4u06fb+B96FURkepMo5OUqEc95kvX0ZHdWYK90XOltGr/cLHsUxbZ56FOKI+c3ZlFc/XxGs4ei96vBXap9nMrEJ5gnN59JIqBaznFOVtzOfj1w20KRMrNc/QoUfVpJSN1xy+cI37j5k1evQa5dNMpNCBa1G+UE99rE393HvydMn9ukLeekj+qLN4PsL1bezHRu3bkwOXyqF3WybHjdcIcB9LkDuWowy5wZC8jim6Tkfn9FSPnBtymHf3dZavYt9IkYvPPuf+/XMQs/dYawxzVqkOOA8qebsvnD0HMa9xuLqMbuTUBHrwlQrmej5zBvdO5+fL934Qcz2bmWU8jjPjY5jfM1fDMWCzimP7gPoC12utgWNAs4tjbYvqPUjH+3enz/cd7zPn492msXSK1gcwi0v3QBwZ5dglRz1dQFFyfj+Os97FnfH9C5jb+zN//IcQ11fw3uZzWA+ZHF8D9t9MEvsX+975HN4HHlOy6XgdeXLI19tYLydfwDzy3/7tmF/24UcehvjXfh0d18c/j8+fw3PYntN5bEsbK/hcNzN75gyuuUkV8Dpmy3jMqE05eNOv7DdT/bIqhBBCCCFGFk1WhRBCCCHEyKLJqhBCCCGEGFl2dVYDh75ENoMugqc8qgVyMgqlKYhb/Xj+tskSehtJOmZvBx29Ae393EqhKzM7i/lBB+RGHn8IvZXH/vLP8XwePaiUi7tnbXKlypR/LU351BKUu69BuTPPX0OXrVrFOug6dIymj+HfGItjcdel57GetjewzOkOebeUY67diu8pfzP1TXRX/uKPPw7x8gruWRz00Yt69ll0kdnfMzML2Remevz0x/4C4jTl3H3k9W+AuJdGF6xG+72fu4T5PTc3X8Dvd/D8V1cuxMp8/gJ+502vfyPEP/uP/0eIv/LlxyEOdzCfYI32k26TA3fuCfRyv/AkOnaFZNwT5/yBCcrvWSJndd/BJYi/7wf/K4jxCs2S5HT3yaVs0P7oWzVsC1uUhy9MxYcpH+I1dDhnKeUc7VOO3IBzFVewDycSVEfUpynNZNwXpe8Pey0gx59TlA7ohSBWJrymaEAOKx8/dv74bxXsiZvDzwzoHNxFY3325veojjZ30GsskzvNTirfA16/YGbWbON3+BI95Wou5fAYa1v4/aefwxynhRzm/+x2uH9RnlbyvV84E88ZPJvH5yT3v7k5fH/zIo69Lon3bG0dy7hvH47tEfnaXfJ8W+TBm5mF9J2I67GMfmaPEto22THn4xvlp6XvpylHMaVTj7WV1TWsAzOzjS18zl5ewbHWh3gveb7T71P/ouNnaJwq0BqLBK35yWWxvWez8fUFgwTW+6V1nA+Zx/e//wd+AOJHH30U4uVlfC5/+KN/AvFTzxyEOOrgOLq9in3WzKy3eQXiZITP2VaIeebPbeMzK5+J53sehn5ZFUIIIYQQI4smq0IIIYQQYmTRZFUIIYQQQowsuzqracrT1yJ/LpGlPKoJdN9a5CkmUvHcZxnKLZZK4THTecwJWSnj+yvkcLQW0Umd2Y/5266sYX7E+9/8Dogb65gL8Nzpk7EyNxuY5y6ZwOuskP/myGO6dgXPceki5VnN4DWWZ9Flmaa9n10n7gK7LTzG+Dbe6sUZzBm6bwzr7ezz6EW9D1UYm5/F/amPLqEr7OmakwHGCcc+XfzvJs/eErU3S6Hzs7CAufbe+4EPQFzKYz1WsphX7/kTz0B8+uxLEM8tLkHcYXHRzBLkbZ84fQrPcRpz0uWX7oX46lUs0/gYxjOU9zJfxP6ztYJO3OYVzPtoZra+gX2mE1EOXPLTrlWx7Tz6/rhffDONOjpKtRo6180G9pdmk3xTOnx5jAQ1M8vkds/16khWzCWx3lKUS5J90hT5Z+xLRpy31fPYFh/r+CMJFio5/3LEqocHYQAAIABJREFUfijngqX7Ru9HxnlX8Rp5r/Jhx8ySV8denieHNZN5+fsyPonuZZnG8iwde6uG7mSO+la/F/fqe5R7NpnCOk6TH9eL0FNc28JzdkL8/kQJc0buO4zX1O/jPajV8Vlx4XLcpUxPU/5b2n+9mKfctzM4JpRz2D8aVXTAL1y8APGRY7gXe4+8x14Uf57QcB7zWg/QMymXxTJ32+g+MhtV9Ef7IZYhSX3F031+6lnM8/3gw2zSmz317HN4DvqtrpfEsbTXp3zP13Du0OlS7lfqT5TuNpZ5OZWmfNZD3PzI83oXHDsnpmYhnppEP7lO6wHm5jF38dY2tsc/+7NPQNyh/Oebmzi2m5k1yWtP0ticoPY1Pou58GdmsUwvh35ZFUIIIYQQI4smq0IIIYQQYmTRZFUIIYQQQowsuzqrs9M4l+1volfSpv2wm7S9uw/IHxriSJXL6FikU+hxtJvoXOTY6+hh/MRjj0F8+DjtpX4ZXUzOdZjn3GiJuIOVy6FrxQ5eu41xSPtRF8npePT1xyDOUt7WMEEuWh9zyrWX445RUEfXbCaPuc9ef+x+fH8M3Zcnr52PHfNmtta3IH7bWzGf26PveQ/EmQz5cryn+JCcjwPydRKUV5GdtXYP62XzMl7DFuVE3NrAazhHjurVNWwrxZkFLGAG69jMzKXRq+uF6Hl/+nNfhPjgkQch3j+B3m02wPadp1yy3Q66Y+dq6FgXS3HfMyInbmUbPaSpqSWIW7Qv+F987isQ/9RP/zjEGzRO8H3qUO6+HuVCTmXJ5crG8/BxH2PnmfOoGsWePKowwjoJyNfP5bHe2YllIZWd1mFwTlMXs9qQVgvbNzutSfZJaWzjMsdyqtow95Y+Q29ns+j57eas1qn8gwH2x4XZGYjT5Ki2KHduIR9v2y6JdeISWOBUmva4Jye1RfuWp3PYx4uTmE+0H2C7CZMYZ8fwGga0f7yZWZ1yhB49jLkuwxXsn2ET2/5OA8exo/cchfjy8hksM/mejqYBjRqWx8xsQL9rFcn/Z6+22aQcufT8YSLKoe0SeLwGtZ12A+tkZR3HnH/zy/8udo6LZ9Hnb9C4dPYK+pu8ZoL7W5/mPy6iNT1UZ9y/HbU17+I5imM9lPpnroDn3KSxN0NrHGo7OJ/qdvGcFy5gHlZHbaU/ZFjzlB+WR5B0CstQyGAfajV3z+n+dfTLqhBCCCGEGFk0WRVCCCGEECOLJqtCCCGEEGJk2dVZPbAfXYOKQ3/n7DLtx7uOtkIvQn+pWIyfrtnCHKPRAF0U9j62yE2pN9C56PTxeAmPcamIOepWV9D3uUw5Hwc+7nXNTqNn68i92q7iHsSZAtbDWAX9nTT5dl3OH0ieU7NL+eEacQ+qMMDP3LMfc5ktzOE1LF9Gt3dzPe4twfHJ4dusYb099eyTEM9QbsDZGc5PGN/DfnsbcxQa5ZNNUr0vHkKndP841vOV09cgbjbQ9+F8b/lJzKmYyKIj12rHXeH5ecxhuHIVHaCNTWyP8wsoejtykhpdqpck1nuf81yST50Z4iX2NinXY4DtZ5byyfbIFYxpjUS/TzkVKR9tktoza46ZHHqQw1ROR0MJ50kl3cwi6sfsnyXIaU2kMQ44XyddA7uefPxhn2HoVsY87rExbI/cZ7rk/kaUt5Ud1WHl4VyuIe2XbhH301tf99fJF9Bti8jl79L1JFOc+xafR3zPr0PuMg2NydTuLnGXxhRHuWnzFSxDvc65YLHtrpPbn0zG3c3xHJY5T3mFi1l0VGenMff4hsfnTT6PFz0zs3vuTX7cBEP6W7mCba9Uxuus7eBYvbGBOUl9gJ4iMzE5Qa9gvbcp32e3gMcLKNdnlZ8dZjY5jU50ZQLzfYY0aAw8ts+wj8+LiPpKv48VOejv3je6NK4Oho0PtG4joPZdpXv5pce+BPH73vc+iE8+/wKVCU/XozrgdSIDF/99k93diJ9ZPTzm8sVlPEdmd5/56+iXVSGEEEIIMbJosiqEEEIIIUYWTVaFEEIIIcTIosmqEEIIIYQYWXZdYFUepwT9tOhmfIYEdxLoN1ZRSO7QAgAzs2QaZXL+yKDPiXjxmDttlMsLlHC/08JFMO0Oit89On5EsfdxiZ+TJpdJNi+XUYBvt/HzG5tY5mIRF8XEkneHKCink5SIO56b3tK0QGTpniUsUwuP+fnPPw/xs6fX4ge9+Zy0UKHbQaH9scf+HGLfx/tQzuM19PvxhMgdSvyepL+tDi7th/iBt90H8ZEDuOCquoyLnVa2sS2kqe0cmcQFV+vruPjvweMPxMp8/4PHIf79//jbECcNF2j0aUFfr4exp6TMlsV6StDqpKVDhyFeW34xVkZOkJ+jBYD33oubVHRaeN3753GhAjM5iQs6AsNxJIqw7fVDEvRpYVCng+3AzMwlKME2if8DSsrfo0UAicGwxTk3vR9bsEXjEJX5Vgn9r5cR4wEtZgjpXg+onhK02IcXQ/U5HtBGB3RNr2RTAK6H4BYLqrjebyabw7YfOIzbPRzbM3SPchn8vLP4mJGmRVlG7aRcwYU8nRoueOwl8QGUzOD1tKl/Jih5Pa3BsV4b6+saPX/MzCYWcSOQ/jUce3PUH7IlvMbpCvbHjc1LePwKbZ5Aq84atHHJ8Xna/MTMBvQcbLVwEU2rifEELcgaMrwDkWE9cztK0r3PZHCuwRsOjY/jAl4zM+P+Rf2P+0dIm8wMIlrAGO1eZl4vFVIlNJo4rna71Hgsvlg1CnmRFn7nYx//OMQnnsfn+hNPfg1iR20honEs5IWjPt6/PY2FA9pghW89b9iS9fHF1cPQL6tCCCGEEGJk0WRVCCGEEEKMLJqsCiGEEEKIkWVXZzWZxbezZfRGJoqU7LuN/kQqhy5DbXvI6SI8Ri6L/k2U4oSz6Eam83jMVJITR6Pb0iXnotfnhOfkwg3L00veUkS54VOUMNzS6ARWt9FZbffQ2ahQUugkOawBXWNriLu1uoHJqrdp84R6E12tz3z2FH5/9z0BrEUerlEZP/DdH4J40MOkzgnydwbREBeGHKIEXXeWHOmVKrqN9eppiLfaeE6XRdn3xafPQbz5OCbPP3wIfdQ333M0VuYebRSQo3vvKfE5bywQJLA9D0grbLPLRX7QwX3orHYauImGmdl9ZXSkv/LkUxBfvYiea7uJ9863sP0y5TK230FEF+F5Ewyskxo5spwc3swsQa/FktFTmKL2GQ7YsyKfjRxVIyfW8WYhvAvBEDjpN7d5T78dDHisauNYxZsCDMgn5ezuXMJhfqmnT+Wpj6TJmw3Ie2V3EL5Lm5/k87RJAG/UQDcxkeCNHeKuW0gbDXg6Z71OyeYpqTqfM0vPwB6NW30aU1o7+Azk9QWlCXQ5r3+INvpo4TiWSNOaBfI3fQrLyAn7M3TPxigZvq/hxgUuiG/s0KnjGNBuUT3RvYz50LfYEMM53gCC+hvde6MxJZWiZ+6w5zaVKcObStD7aWrKzrAvsIMacX/yuzuxk1PoTw9bt+FpDIh7sngfmk18Lq+s4mY/S0uHIK43+XnE6wPIqx9yH9lj9VQPfN282UkwbBeKIeiXVSGEEEIIMbJosiqEEEIIIUYWTVaFEEIIIcTIsquz2miQB5IoQlgsoG+XyqHPUKAEoJVK3JFq1NoUo2PRIDem38G4lMacjllyV0LKQ5ZM4vw8TdP1VIZzEcbn8/kiVltAtRiSR5jO4QfKY+j3bG2hX1onB6Q8gdfYIi/rzIW4l3jquWWIZyfQI5zdh2WwAM85VSnFjnkzhSJ6UxVSWUrTmKuT88Fl6e+kNOVcNDPzOXKv8viZQQfdxnqd/LM8XvPMEfTFjuQx5+GZ8y9hAdijyqNbduUa5jM0M5ucGt817rXR/ep20R1uUt7VLvmb/S46Scks3sfZBfTRLl7D/mRmtnoJr7PTwDK8dPJpiCcnyXEbR9eKcXRvHYnfPUpG2eniGMC5Bdl5Mot73J5crh7lHO1SfkJHnhTnNmYXkz2rAeU+ZpNrmIXFox87dOy8eUfuV5I8vQSNz7HjU8w5E6O4fxZTb2ksCng8pPfDftx3/DoFcjOTVEs80mbJl200sC9wDlgzszTlHc6R1x57n07a3sE1EbMzByDukNM6VsAypqbJJ6Wb3rd4Lk1+XuQo73aKxj1uXH1qR1PT+JxOD/D5k6A1FRl6TnsfL2M+j8fMcZnoXrTJfeSY4XzmnmR9zmMcz1mMFR1zWM3MkrvnGeY+z59P0BiQos7CDnnMo+f+SN9PuHiZuW1wk2cXP1fCZ9ziAXpm0jnbPZpf8VoSqleXiM+HeFzh73A/5XoZll92GPplVQghhBBCjCyarAohhBBCiJFFk1UhhBBCCDGy7OqsXr6IcbeKbktpGv2GbI7yhaLmYhMT8dM1KC9YtYrx9maaYvw+7/HNuQxj3gjlJePZOrtsiSF5A9uUG9ZTerTUAOshbGEeu4hylEbkEFUb+D5pJbZFnu+Fs3FntbqJbmSviQeZq+C+9/cexP2pa7srRtaqYw5TG5DP4/Dmr66iF3nm+QsQZykfoZlZmvaXnppB/3NhqgIxe4yTFXR9OZVrp435Qmdm0HFdXEA389rKCsSnT78QK/NSD/PYsY9Tr2M9tFrolNZ20LtlZzXqUQ7GDPptJ0/gnti9LvqfZmYzM7MQLz70AL4/je9PTWNbydI5GXaWul3OD4pxj/IWc5k5t6VZPAcpO23sSWXJVQzIR4vIcb2Vh+Vof2s+PzuuZmbpIY7lzXQ6WA8hlYmdOb5GLjO3vRbl74zlwrS4J8rnDHt4THZYs1ms55tJcd5Jdvspx/Ct6nRYntg0r1kI2cGjZxYds1LCcYtTQGbT6MAOaHDOF/H9PrXlDuentrhPnacEnylyfZstPEa2hONWu4fX2KYypDzWUYLacpDANmAWS4durTbWfbWKYynXezodX5NwMz1ai8Jtk1VJdjVjnuSQ57ajPs85hTlPMa9XCcgpTeUw9gl87meG+J1UIvz+kBymXI/9Ht5LHgf5860e52nFeu6EWObYmED5bT3PpyyeV5Xv9W65l83i+ZZfDv2yKoQQQgghRhZNVoUQQgghxMiiyaoQQgghhBhZdpUJohT6b/30myDuDshfCjFvZbaCvsPYdNyFGQ/QsZhokQuzhS5jdYPyuTXxEqKQ3BjP+RHx+B3am519i0Qy7pnVO3iMdoPyzXr0SkoB5iwdBOgl9vt4DZkCuivZFDpLY2k8/mGL7zf94MPoFR5/6GGIl+65B+K3vA09qMtX0ZVkBuQZBvR3T7KP9VZOYZ09+eXPQbyyim3HzMzRdb/lLW+E+J1vx/a4s4M+6LNf+yuIm+QEnr6EuWjPXbgAcZvcME+JK7NlzD9qZlarUc7cbbyuZg3dLrYGk+QIVUro8ywcQid2fHIe4pkF9EsXXv9grIwTZWwb7FLG8ldSvlnuUwznG2RHlb0q3kM75jgF8T7I9cZlZr/Rk3zYpzLwOdntcuSzJSjHacAO6xAflJ20W7lefA23clo5t+St6iTm8w85Zpoc1HyG9oCn7w+77q+TS2P5+Pye1hNwHZfL6GYOc1b5/OxSenJWK5TLuUi+qKc1Ee0utQvKWznoY38vFdCBHaIlGt+FJnnBqT7WQ7uN74cBusgbOzgGNTbxeTM2hs/1zSbWUZaTz5qZ91gv21s4NtZprMxRvXIcP36sJUEUhZyzFOMMOek8BpmZRRG+lqL2yO0padReyZ2nVMtxz53GjIBzO1Nb5VzPZvG874kUjhF8DO5TfE19clQD6g8D+n5IcSJ2n8wGt/D9h7m4UIYh1z30c6/oU0IIIYQQQnwT0GRVCCGEEEKMLJqsCiGEEEKIkcXdyicQQgghhBDim4V+WRVCCCGEECOLJqtCCCGEEGJk0WRVCCGEEEKMLJqsCiGEEEKIkUWTVSGEEEIIMbJosiqEEEIIIUYWTVaFEEIIIcTIosmqEEIIIYQYWTRZFUIIIYQQI4smq0IIIYQQYmTRZFUIIYQQQowsmqwKIYQQQoiRRZNVIYQQQggxsmiyKoQQQgghRhZNVoUQQgghxMiiyaoQQgghhBhZNFkVQgghhBAjiyarQgghhBBiZNFkVQghhBBCjCyarAohhBBCiJFFk1UhhBBCCDGyaLIqhBBCCCFGFk1WhRBCCCHEyKLJqhBCCCGEGFk0WRVCCCGEECOLJqtCCCGEEGJk0WRVCCGEEEKMLJqsCiGEEEKIkUWTVSGEEEIIMbJosiqEEEIIIUYWTVaFEEIIIcTIosmqEEIIIYQYWTRZFUIIIYQQI4smq0IIIYQQYmTRZFUIIYQQQowsmqwKIYQQQoiRRZNVIYQQQggxsmiyKoQQQgghRhZNVoUQQgghxMiiyaoQQgghhBhZNFkVQgghhBAjiyarQgghhBBiZNFkVQghhBBCjCyarAohhBBCiJHlrpmsOucuOOfWnHOFm177KefcZ2/Dseedcx91zl11znnn3NKrPaa4c+xx2/igc+6Lzrmqc27FOffrzrnSqz2u2Hv2uF38M+dc46Z/2s65gXNu6tUeW+w9e9k2bhzrZ5xz551zNefcE865d96O44q9Z4/Hjfc555678TzZdM592Dm3+GqP+1rgrpms3iBhZv9kD447MLNPmdkP7sGxxZ1hr9pGxcz+dzNbMLN7zWzRzH5xD84j9oY9aRfe+//De1/8+j9m9q/M7LPe+43bfS6xZ+xJ23DOvdXM/k8z+yG7Pn78hpl92DmXuN3nEnvGXj1PnjezD3jvx+z6M+WMmf37PTjPyHG3TVZ/0cx+zjk3NuxN59yjzrmvOud2bvz70VdyUO/9qvf+V8zsq7ezsOKOsldt43e995/y3re899tm9mtm9o7bWG6xt+xJu6BjODP7cTP7D6+yrOLOsldtY8nMTnrvn/TeezP7bTObMrOZ21JqcSfYy7nG1ZteiszsnttQ3pHnbpusPmFmnzWzn+M3nHMTZvZxM/u3ZjZpZr9kZh93zk3eyQKKbxp3qm2828xO/u2LKe4wd6JdvMuuT0T+8FWVVNxp9qptfNLMEs65t974NfUnzexpM1u5TeUWe8+ejRvOuQPOuaqZtW8c//+6TWUeae62yaqZ2b80s59xzk3T6x80szPe+9/x3ofe+98zs1Nm9j13vITim8Wetg3n3HeY2U/cOI947bDXY8ZPmNl/8d43bkNZxZ1lL9pG3a7/4fJFM+ua2c+b2T+68SureO2wJ+OG9/7SDQ1gysz+xY3vfstz101WvfcnzOxjZvZP6a0FM7tIr120646huAvYy7bhnHubmf2umf2Q9/70qymnuLPscbvIm9kPmxSA1yR71Db+WzP7b8zsfjNLm9k/NLOPOecWXl1pxZ1kr+ca3vstuz5u/LFzLvm3LedrhbtusnqDnzeznzZsHFfN7CB97oCZXblThRIjwW1vG86515vZR83sJ733f347CinuOHs1ZvyAmW3Z9f9lKF6b3O628YiZfcx7f9p7P/Def8rMrpnZN+xDi286ez3XSNp1haj8tyrda4i7crLqvT9rZn9gZj9708ufMLNjzrkfdc4lnXM/Ymb32fW/jG6Jcy5rZpkbYeZGLF5j3O624Zx7wK5nivgZ7/2f7EWZxd6zF2PGDX7CzH5b/4v3tcsetI2vmtkHnXOH3XW+w8z+//beLFay7DrTW2eMebrzmHNlVmaNrCqyWJxVktiSWrLVbLf8IBuwDaMbNgwDRsN+lO1+8ZsfDPip24Bhd7dbgAE2RIltSU2KJbKqSNbMmnLOm5l3HuLGHHFmPxSLyP/fUXGzKEodbK3vbeWNOLHPPvvsOBn49r8vish7v+i2K3+9/DV8n3zDsqxLlmXZP9UL/lcReeunv7L+e83fyofVn/JPRORnOWhZlh2JyG+LyD8WkSMR+R9E5Lc/jpKxLOt9y7J+f8LxhiLysXN29ae18svJL3Js/GMRmReR/+OBTE1dYPXLyS90zvhpPuKL8tFqb+WXm1/k2Pi/RORfyUe/tnfko4U4/yjLsr8VbuK/h/wix8aqfPTjR1dE3pWPYjP/3l9f06cHS/9DryiKoiiKokwrf5t/WVUURVEURVGmHH1YVRRFURRFUaYWfVhVFEVRFEVRphZ9WFUURVEURVGmFn1YVRRFURRFUaaWibse/J//6B9CVMCwH8LfHRefda31ZahbxQLUT9Z84zPu/eQtqL/16tt4jCDCz3ToMy0Lai+H8aYz83NQVwv4/kdO4U5oX/vi56COI/x8EZHDNu6K6FUaUH94Ezen+M73XsUDUL/lPKxrnge17yZQh9SmOMI+EBGRLMXPcHJQDzK8lscjTIWw6bS/9fIP4UP+xVv/AN7w8nf34PWV/KNQl4qYWezRhhvlEp6ziMhcDTdsaRTXoK7XalDvHN6D+vbBO1BXV/G6za72sU25AdTDfgvqfB7Hr2PVjTanSQx1knShblTxHHK5ItSu4OvbnQDqoz3st1EP+2AQlKHOxEz7OG7u4HsG+BmdXpuOged03MR+/Od/8AqMjfULj8KH2hleW6foQL1+CecNuqVl49a2MGmK/VCpVajGeaDs42cuLy9B3ephvx+1jqGemcV5JDzGZLre3hHUjQq2R0Rk6TRuUNOLR1C3j/AYvS6OT4em6yjAeaHdwetWaOD8GyV4U0dj5rYkxWNmVPsetqGQx34OQ5xX3nn57Z9dzf/lzzdgXPBnJSnOWTwj+DbN/Y75fRKmOHi6IV4nh3+eGeE9Xy3iPFkt4/nFeCtIN8JxZdPgjQTPMc3Mudoa82+/SDjxJ5OUXwBlOjYh6IQ2nhAqxN/T/+NvnoF/+IM/+O/hCO1dnKNGfbxX3FwJaqGxcf7CeaMN587Tv9F5bm3eh/qD116DeuP2bagTGks23Ru5As7t9Qp+B1bp+4trEZHGDD5b1GozUBfL+PdKBY9RKGMb8kWqC9iPjo9zRkrXnUaOiIhkJ/3kmdD4ovvcppvys09dHjvY9JdVRVEURVEUZWrRh1VFURRFURRlatGHVUVRFEVRFGVqmeisHm/dwRcn5BS55Hxk6L7dGKIT9eTlc8ZnpCG+Z3EO3bDCkL0q/Ex2YQYBHq/dRPesZ6FDFIzQaXrqmeehjgboyoiIHB7hMRfz5HmEHagLOXI2yPxYqKBn+Pi5C1Af7G9BPRyiX9froUMoIiI2Gl85F2WrlSV0WyJ/AeqbH2yYx3wAUmClNIdt+Mkbr0C9vvQM1JUS9tkoRPdLRGTYxX4b1vFaxxb6Zo0VHM6PrGM9zKNX203RSU076MDlEvR5MrqOUYKfLyLiOngtZ6o4nos+HaOPbmOnj/5m9wjH0r3r6EM7ObKIPLxfNrd2jTZWynievS7eE3HMLiA7R8Yh8dURvp7dxCG5k7s7eD8tzGG/513z/9S2hePHS3H8BMc0NubR1VpbnIW6VMCxMujQVtsBju/Ll9E/XfoCOtrlAt0gIpIr478FKfqdQYA+c6eF9zl73gfbB1DfuYsXxp9BR87JYx8lFn6+iEihio5mPodjoZLHa+O52KY0/WR5MXNwTmIfjn86GQY4Z40SfL0/5rMsG1/j2tg+KyXplD6UndL+COd/x8L+sGietcmdtPkcx9w71kk+6KeEe4XvHof6yCavNoqwFhGJTrrnTzoFFtGJxjyuT5ifXYT61NppfP0MOeQWXgfLNX1mdndH9N1/aekM1OcffRLq29evQ90+xjmi1cT63l18frp/j56nqEsKvrluIwlxHvNcvIfzeXRWXVqzk6/g/VqgZ436LK7Zqc/gdajV8fjlGs4pIiIV+rdCGb/THFqX4dCc4Trmd/849JdVRVEURVEUZWrRh1VFURRFURRlatGHVUVRFEVRFGVqmeis3hlRNucQc/x8i3zOBD1Im/yew7voDIqIvLG9CfXVffTXMvKW2FHNU85fFJNvQw5Rnlyy1hBlnB+/ewPq5Vkz+yyI2b9BFyZHvep5k72lS5T/duYU+jn1CjofuzsbeLjI9GrLDXQfEw8dv2IOHbyVOXRZ7jv4mczWPmZCrpxFt8Vx0FuZKbOvjN7i1p3bwtzZwqy91RX0d/oZfkbDxbETV69CbZexzUGEjlC3hWNtxsU+8Mk3rdawz0REKgX0DgPKsgxjdFAlxsHQ3kOH6Pg2Dqbrr2MOcWkd27x6Ad3j/Jj82k4X2xCMyOMj/+vwCN3IcMx4e5Ccj23OyDVMKHdPYnSWFhroo42aphs87GGb8w6Nb8oTvHwJPfBHLp6Buk05q16eQxSxzVeewPefPYOuVxhgRqqISGZjm21StVzKV05Dcgkp5zrsY1bs50eXobY8nBttyrdNfDNn1abb3qa5y6exwbmi7AU+SERjPaNxwLOqTR3E70/TMe1nY5ODVWndhe/j90HMedQRXrMCZWLbLp2T4ajS3x8qw5TqEzJM2QflHEv+zrQtPAczh9X8wAmXdewxPu3fL17CsXvjGn4PH7bx/ixSnmiugONyNDLXcfg+Po+klMHbD3CemV/A79AXVs9AvXVvA+pBG9dAvPDFL0G9s4drT3wPx1q9bGYzv/cTzHp96TvfhjrZx+9Nm3zkjK69Qw4694lDOcUe/d3NmS5+kdaf1Mg3rszgd2KjgVmxs7O4fuDZx9H//xj9ZVVRFEVRFEWZWvRhVVEURVEURZla9GFVURRFURRFmVomOqtDB/2Fpo0OlZVgpuks5WeVq+gxjvrovIqItLq0L/kIPaSMPjNJsHbo9S4/f1PmY59yXcvk0vz4nZ9AffECum4iIo+eP4Wf6aPodeYMOqj9FH2avR10ADtddGeEsgyf+wrmvb392ktQD3nDahHpRtimoz5ei5kheoerDjpBo97kXLzr1/H1Z86ha3n2EvbR7Rs3oe4P0CkqVUxHtkuO9HvX3oW6vPII1LMVdPpiG92tzdvorEqGn9nw0TvMhLxIH89xpoZujohIr40wcnpaAAAgAElEQVSOz9UP8RiNEnqGlSqO12gWPb3+Fr5+d68O9dk1fH2xjMeLU7NfQ/K5XB/fc9zEazugfbmtE2LxSnXK0Uvx+JUEXcoCZQNy/GfRxb+LiIxG6N0OeodQZ0X8zP1tPMZblJE7onlhdgHd3+U1vA7LK5QHXcfjmymPIqSLSd7HjmSHM+pjm6SABwjoumUB7bmd0PSew3u6sGD6+HEB2xDQxcisyft8p9knB3IabuRJIiRhWQ/hf1JmI7+G/c0owLnXFzxfn8aeaYAjkbDDipwQN/pXeNMnw9co4j7h14/d7H1y0Cr3K3PSlW5U0Nc8dwHn9s37mC/dbOL6lyo7rJR9LiLiO9iKEt0/wxGNdXLt+Wu2VsPv1JDGUpzg8dZpbUohj3N5uYi1iMjc+lmoB3Tt/uybfwi1E+Pffco29ijbOR1ibVMG9ogc2HTMdT7gMX8TfWOh9S8Oueg58mD/8//mvzI+Q0R/WVUURVEURVGmGH1YVRRFURRFUaYWfVhVFEVRFEVRppaJzmrOwr1ul4sobdTJ4JlpoCdyJ0P3rVQwvZccOVBF2v86KqHPEMXkVATodSX0/F2gvEU/h21eWscstZW1dagPe2am5G4H3ZTnn/8c1M093I/9G3//i1B/+4//FOpXX/kh1KcefwbqF598FupbW5itdudlzGITEWmH6AD1KKPw8mfxM4YRZpTOzZme4IPcv4fucCbYJ53Z+1CHNvqniYvXsU7ZayIij1xCX2dvH4/Rp7zPn7yPTmpMvnN9Dj0oofHp5fB4jRlsU7mInmK3Y/o7h3s4HtMQx3O+itelE6L39O4I82iDGcygsxfQ3Srm8ZyPW3jP7mzjOYqIxJRdHAV43r0++qBxzO6umbX3IGceQ5c3N8KxF3fxnt/awnzCaz/Bc7Izc5oKOuicWjGOP5v8zTuv49i5R1mwMbmWc4vorB6Ts1pK0SNfqGJO5NIyvl5EpJijPGaa+0Jy13sh9nvYQb+st0HuO2VUh128rkPKNp67iHOdiIhNc3h+AbOErTr6ZhY5bR6Hxz5AROaidYI7aeSusm8ama6+43D78PsgEVrzQD/XFClXliIkJR7guAsomDaQyUL3OLMzMzzfh9sr/efFzFWd/PdfDJOd1g/ffQfq6izefwWXvPqjfaiH5F4uLK2aH0LfBxG5uSH5nlaKtU215+Ec0mhUoX755b+AukIZ71cew+eGYEy2OUUtS3Ue55XIxQF6fIxzQJFygIvksOZonZHlYht5JKRjhkbGscA8nsMu/R0P0h083HjTX1YVRVEURVGUqUUfVhVFURRFUZSpRR9WFUVRFEVRlKllorPql/DP5yrokZwll6zmk+fY3oSyWDddt76PDlDqoaTx3NPoVi5S/uHtm5jfef8e7r9rk6ORxehx5cljeeF5/LwDc1ty+fFL34P62jXMFE2G9KYSeoktyk/sRfh/hps76Oz1U8rejClDskV5jCIS5NE1e+Q0upD1RcwUPTjCz3zxxceMYz5IHGC/tvbRGYoG6M7kSuilNJbQB81ypn+2cAHPoZNiPmiPPKWC4DGPjvBaV3zM4ltZw1y7SNCDaqf4/n4TszzzjplT2aPI3EqV9h73sV/2+ziev/1NysHLtqE+7+PrnQzHxuE2+qbhyPSBHBclo1FE2cbkBpYpw9BiSYn4jd/9MtT9DezXV/8NOtpO0Id60OFsZfP/1AWyqWpFHI8lmkdmyQerF+naueQJRljbW9ivb//xy1DfffsDqL/29S8YbX780TPURvwMv433gHWI53B0D33k0dUdqPu76LCOKPdxu4Nu8N0b6JWLiLiz2C/FUzh3Xfn1J6D2irSmIJmQs0rDhnRXcchrNF9vT/y7iLmvvUteoU2f4VD2ZpTgNRj10LfrbWOfz118HN8vnHOM7UvHSH98Hhbtz84K6Ulur3F8rn+evNtPrbHSG074jGYLx+57b/8Iao86cunsaahD+nuxjFnlIiLFIq5PyU64VoMhXnvWsSPKZr76zhtQv/m9P4O6VMI2Lc9jexbXx2TD0vh94spTULv/6X8N9Rbl0bZb+J3V7eAc0qM5od/HuXg4xDkkou8KEfOes+g+9cmr9T2cq4tF09Udh/6yqiiKoiiKokwt+rCqKIqiKIqiTC36sKooiqIoiqJMLfqwqiiKoiiKokwtExdY9UIUYWsOCsLRIS4Wud/CxU1feupRqIchyrsiIqskNeeLKOt+vo6feWUeg9kHJKwf5lD4H7SxjQmuXxGXAmtP37sDdaFlLvyZmaeFOe+9BTUv6nr1gw+hvraNi2ZGMYraW/dwYdr+Ecrnn/vM57HNdTPc+3/7l/8a6nCIGxW88RqK13t7t6B+5lfx2jE5C88xGlKg/hKGF2/t7UHdGeFYyezrxmc89fhFqF/4OxTM7mPAfjTA+vp12qjgGPuxQCHNiY8LWjY796CeraBcvtLwjTZXZkgmp/8P9il4+tYmCvG3f4Dh9WEXr4u1jn8f7OPCn+XTKKsX6mYbxcZrZTv4miItVgppIZtnTxbiH38aA7lvDnF8t49xAeJsEa9bTBL/YRcXBYiILNN5XajjMVwKf/dos5FGFReD+gWcZ3hzkXwer2uphMta2vvYxmt/jIHgIiL1XdpIgELE4xEtrgspcH9ImwrQ3DegxRRCc2vSxn5vHZobRhQPcI6OWvia4DO4UNM5g/2amOsvfsbWHbyfHAsb6NEiN8vHcWhRgn/OM8e2ndJ1D/A9KYWg5x1anhTj++MMPyO3dAbq4wGO7T4tLnHp3sosc6FRSiHqFo09mzY2MJLZjcVLtEDLqGViPQ7e/MFY1kUB+7zoJrUmDAwRqdZwYd+dAS6mPdzF749hiserzOHCU8syl50V8njPz87jImPXxfEW0ELpQgGv5Y3r+L3+6g++D7Wd4FhqHeL9ub2JCxxzFdwARkTEL+Ii43oNFzx++Wsv4mfSdRqOaPHqAO/nfhe/T/bo+2jjDj4P3aAF7SLmwrE12lhpdhY3iSkUcC6dmTE3BBqH/rKqKIqiKIqiTC36sKooiqIoiqJMLfqwqiiKoiiKokwtE53VeQcdj1VBp6haRU/s7WN0LY8D9CFOL2EIrojIf7R/Fmqvg47F7A08Zu4WhjIn5K6cIVXFS/AfbBfPKSH3Mvjxm1DXYjNwP50jv43ThCnUvOqgdxJQ8O4MhQ0XM3Itd9EjWb2MLmelRJsxiMjnzqM3uN9GH263hz7OYIDO3e0bN4xjPkj3GJ2i6hw6SkcdvE75Ml6HXh9d4IhcMRGRqx+gL7Ozhc5bpYLnvbiIrszCGXSMBnex3+8foA9aqOB1nJ1Hp7BRJdfTxrEpIuLSxhi+jS5WHKJznUY0YFN0rC8/gffQo2exrhRxfDbm8RwGAzMcOwyxX7pH6IMlIR6j4JOjmky23Go1vKcOD3HDCc/GNpVpnjlOaWeFDPtdRMSnJPVTFTxmIYc3VUj/LQ9C/Iwu+Zx+Aee2zMPPK1rY5oU5vK6+a/bR4D564zv76FDHJNTbNoWE0wYQbg7bxL500MGxUcxhm5s9HEsiIoM9nAdqFTxm2SLP28b7OJwwNN68h3OCZHjPs5vpsf9JniQ7hh+9BxtA+y7IiG63hRre42dmsF7K41dkuYjjbDjCsWnRBi7HHezjYWiO5STGPnTIxfV97HP2QR3ycIMRXneL+s0mnzMIcdxxe0REXApyL5DDbZMTzsMgPulnMRfPsd5Aj3Hv9gbUefJJO5v43bBHayRERN54E7/br1DAfrGE1z4MaL6nsfOTN38MdZsC9mP6TksTdpORcZszRCE+3/Qy/A7jPP2ch9elQOdUa6Dbmycv3Lex7tC8+OKL5402Li6ik1qu4Ge6eWxkmmI/5PPm88s49JdVRVEURVEUZWrRh1VFURRFURRlatGHVUVRFEVRFGVqmeisPlpB16B0hDlhjo3uwcW1Nai7e+hkSWZmn62SY1T08TUOuZQWZcxRbKoEnElHvo9HXohLvqlnoyMSVUh6EpGMsvXiAI+ZkI2yaGMrX6RMx9BCRylZQQckv7EB9YDjBckdFhF57NELUC8PsA3LEXpJF89j5tyFOfRsGStlF5ic1CH6O4uL6Mo4gi7n9raZw9fJ0GXpHOM5uHkcX0d9rGsVzKTLl9Hnqc7ieC3k8HZYbCzT33ksmG2OooRq9DUzD8dn53ge24S6j3zt1zF7Lyf7UC8v4XXyqY3X3yWfWkSalHM66qC/mZFrVaOxkIzxix+kQPecRa/vHuPYsMlZdSmTMRsjvMUxtimK0LUqFem+pozObhfdL58cvEoZ2+T52K/9PjrbkuDYmambrvAowHmDYhglCui69HHu63bx78USTgSNMvbJfgfvlzy5Y1lq5qyOyJG7fw8927P38R5bOIP3UJKajv/HWCXMp+Z8UDb2aFo15vpkXEJohvNakb4vIgqCLQ3QS8zK5E7O4HVdrtD3Ux37/LCN4+rWPl6zm0dm1rjl8LyC77HoOzJHOd6eTX42uZYcOcrfwuysRpE5r7FPzLnDtoVtyCg71je+Rh+DakTfwz6NVfZy4wjbnFFG7+42zpMiIrfuYK7pq6/+EGrOR3cd/Mz5GRq/EfazS9NUt4P312yF52q8fy1+dhGRhHKD05ByhMlvrtXxO4892RE51tevYVbsy9/7LtQbG7ehXlnBtTAiIofH9B3Hbnke50L2nzlX+1f/zq8ZnyGiv6wqiqIoiqIoU4w+rCqKoiiKoihTiz6sKoqiKIqiKFPLRGe1uY2+QhDTvrMOZTrW0MkoDNBFGH2IuZYiIolDezGXsEm2g25KLuasMnTLYvJiE8r0ysiXOGmfZHfhnDCVFj7jjygmLDyN3kgjRr+tRHuAxy30rHr7tP/79stQ77z+DtTVxzB3VUTkaBfdsrCIuXUxRVkOjjDfs+OxIYb0uujjOH3sk4qH1zEaoIdlk5dVyJmum01ZlpUGOkOJg/02DPGcB3t4DmdX0ZOqFdAXlYj8tjaO50aJQu3G9NGA9mIWF9uYkgd1+yaOx8YiOnPPPIvOakEewTYmOLZGfRz/cWTmDYZDvHY5Bz+zUMKalTrLNj1YbBSes0dupkf/R67X0Lkupnjd73dMzy8gR7Q7YpcLx5ebw3Ni521tHd3L2izeL4dH6GVF9P6YZtIoNMcG72U/GpLDStmRA8pJ7TQ7UGcxZaDO47wT0XXo9XE+HgSmexzFeA+MDnGs3LmO3t/cC7S/OgebPthecnYz8kl5P/fUmI1ZvjTXQIjg2IwtynTkbNcU+2i3jRNjSn/faOE1CihXtUV93B7g+wdjMoo7dJ1suj+4n1ybj4Gfye+3yB814jwzHJdpaj4WZNxu8tAz6lf+kLGX6gHqc7imYe8GupQuTUIjulfExzZ7rvmBvCahx2tPyJ1MXeyXTgvX7CQ019fq+P0U0nVjZ73Xw7mbHVkRkR5l5lYpwzSN8Noe7uJ83+/j/XvtOvbr66/9COrbt6/h+6mNd+6az3Aefden9AxmO9iPDl3LmHJ9/+d/8j8ZnyGiv6wqiqIoiqIoU4w+rCqKoiiKoihTiz6sKoqiKIqiKFPLRGf1qId5iPf7mNEVk8/jW0tQFxu4X/bR0Mz1W2JfboTPz0kHPZKAcgCF9uQuXcR80RH5or1D9L5ylBfqkFcSHJhtlhy6YRZl7bmUi5d2sN8Kj5EH6+P7i/voTfW3tqBuXb2Jx79neomVGfQAm3V0W452sV929nGf+7M+ZowyTg6v03BEexjfxX4LDvGcFlawj0oFHAciIm3Kaq24eG1mFtF9OTgg1zKhfNCAvKceek85C/PgbAcdpOYheZAl0/k76mIbh+T8iIvHvL9FOY5r6CvnyzheXfKdh0PKzgzw+GurpjtZI/d29y66V6UyHZNygi1zS3agQ/5zn+pGEcdmnnJZw4DdMbOfBxaOp+OAnOkqZVGSNFctoe9Zr+E5V8roWbVb2IYj2vPdERxr8zNm9jEzIh9NQsqQDvGe7fVwHulR1muOchsT2sz8kDzzY/58ERmRAzeK8DXbW+jtmddqTPbpx+0x9pwnr5Hay3uIGx7kmFxKi7zWmObiio3XMU+HOKQ5YUT5vTatVxjQNcs7dA407kq2OZZDymZOEsoGZ4dVKHuTP5MdVfJ2M1bOyTEcs0W9pOP+8UGsyas/jM8k1tfPQH39tVegPmrj/TY8xnG5duYU1PYYSZazYvklnA2bUmZvTBmnpQLlgNP91e1jGwv0+W+8+SbUG7RWRUSkUsNnjVIRv6N8moyvX78K9XEL13FsbNygv6OLn5B7zL60EdIrIknC7xGqeXzhMfm6fBL6y6qiKIqiKIoytejDqqIoiqIoijK16MOqoiiKoiiKMrVMdFaPaR/Z3QE6UhHlH84tYm5lto7ZabmG6XHlOuiFuNuUD0oOUY9y9BLa7907je6Ka5FnUsfjRdfvYU1O7Mg290mufOUK1APKX5Nr6I0I722+g68PUnQzvSXMLlz66uehzhXQvWxeN7PP6gN8Te00elD3KI+t4KBHwnsOMxb5PBnlXM5X0SV2huT/dNG1SXPmUAxH6AAdHuJ4yzzywTz0eeYXsB8XZrFN83UcnxJhn3mUDxc5OP47fRyrIiKbe3eg3t3Efm6SXhwHT0JdqeMxdw8/gLpmoVtZ9HEsLqxg5u7KqnnPWTG6Vt3LeA+F5HknFuV/BhTSS6R0D0W0p/1MGdvUbqGXezBEd2uOcotFRBolHD+7m7iHfXWEznXOxdfP0j7f5SL2iUsZ0tUq/n37Hs6N/f4JvqWI9NiHpOzhlPTiY3LdW118QZph7e7ivOJX8H7o0RqDtuGQigTkLwbkm40oVzQmpy2JPjmf2SYnlXNVWSLkv7PrZrxfxIxipd9jkgzrHGUG91y8Fzrk8JYKtO+5j23KUeZke4j3QmlMDm2ZMkI3jrEPB3QOHjmqfI4W/wTFvil32wlxtiLmr1p8LbLUdHE/DUUH769lclgjWtMQB7yWBdvTontHRCSise2Rc2ol9GxBTndsU0Y7rbdxc/h3l3KMAxp7791Af/TojbeNNhcL6ML7Lo6VjM5pSPmzKTuoJJQ6Di9AoPFJmb583UVEbM6HdQwZ+IRjnBDC+/HnPNSrFEVRFEVRFOXfAfqwqiiKoiiKokwt+rCqKIqiKIqiTC0TndV12i/bvoN5nwVS1xLyRnKUAXbcRzdNROSV+5jvuUKe4qOCH8I5q0PKIA3fRMdvyFl+q6tQjy5iNuwgRifwyfPoBIqI9G30SIbbG1D7bcqjraL7GN4jT3YPXUxvYR/btIhupTdTg7rxq88YbWzd34G6PocuyjPl01D/+Q8wCzNXR//YIMJz9MkJLFN2pkd7uXNmnZUzHaNiHo9xtI/XPqG3XD63DvXq7FmoXdrredSnLE5BX80i96ZH4/vaHbyOIiI7Lfw3mzIU0xZ+5kyG4/tiA///GA/wJEMXPSsnQk+Rsyf9gtmvi3OPQD1XRc+708exEFDWZsmdNY75IC47dhZe+3BIe9530ZEdZnidv/TrXzA+47Er6KT+4F98G+rDLezX5RruqV2r4D0chthPAfmcaUKOXEBuJvluR82m0WZJ8bzZ8+v38BgtmkcSC+8Hm+653SOcX5freM5SxPHdTc0M6SCl8WfhvOEUKbvY0E4n5XGygzo5fHOcH3fi39mhJa91RNcp7uH9k1k4t3o5PN9FmssLDvbXacr9PruA3yclDnYVEdKj5fs30b/+3g1sYzOkbHD+jqNzjmN2BvHzDPd3TL+yG8lwHCczTi9+kBF57asrOJeX6zNQD/fw/m4eo+feH5gZwrwHvXCuL93jaYKvD6mfjzt4v/k+3o+cGzykOaMX0JwTjWszzhEOZ+7y/UfzP+fNskvP182eeP+KJMkJgbkftWryXw33/CEOKfrLqqIoiqIoijLF6MOqoiiKoiiKMrXow6qiKIqiKIoytUx0VpdWFqHu0r7QxQYLE+QpkrOxc4j70IqI/LN33of60iw6Qv9tHrMCi/R4ndH+2M130VltzqODdDtAP5Q9lJWLmM15qoHvFxEJdzAss0x+qMWBiV3sh5xNWX6UjZbcvg11to0O03EF+7l0Cd1iEZGVs+ehHlGu6jztMfyZxy9AvX7WPOaDVGkv9TzttZ65lIFax+saJ5RhF+N1ERHptbFfnB450ZSJKEPKjBuiP2a56OEmMbYp52EdkcPURpVTss5lo82FCN2qQoZtyjnoTO+2Xof6jIt+8lr+cWwT5f4OKfu4HeJYTJvmftNWiq5VvYR1auP46nbQm/JLZu7pg+QyHBtL8zgW30hwLB4LXueVx7APvvA10xt/9DLep7NFnMr+v//nO1B3WthPgz6O/+Yh9kFI/ljm4sTTDdhnxuvSGJr+WY72dE/IoWuRtxeSa+j56CuPIvzM4xH6ZB451kOHXHsx77mQcqwHlLnr0NxTLGGbkgmeKd9P/EuJTQGhJzmrY2U3znSkDyF1XjzB83uujuf31LPPQb1QxQOk9AG+jY7v+jze//aYPNI4xve4l/B7tzPE9/zpLczlzihLk/NCXfKOM5u9R3ZWx3iJ5G8mdB5GDit7iyc4r8EIHVSXsjsbVZxzYno9f9xgaGZB+y72w5By5FO6n1zOs6VTsCmDdDTC+5fHMx8gDD85k/hj+B4wclO5UeSknpR+axyfOvLEbOSHwLiP+R59yOPoL6uKoiiKoijK1KIPq4qiKIqiKMrUog+riqIoiqIoytQy0VltJyjpuRn6bx7tUxvS/vKtmLLQhqadEGd4jI6HHuKWh/5bnfakD23aoz5DV6ydokeyuY+eVtVG5+qYNMg/2vojo82XKKv1/AweYzaH2a39DcyCTYa0xz35QMfHB/R37LeQ8kejNrrEIiLhT3Df4SKZIUEeXarTVx7DY27fNY75IE7AeYZ4DhFlZQ7YKepRtqxvjo2qhdc+Rz6YH2OOZMnB7FgnQFcyHaILVvBwf3hJaI/tBI2f5Qoef6n+eaPNwwSzK/tNvAfu7GO/Nlx0tmvke55awHP4cPcW1LaFLpdnYb+HgWktjciBG5Z/BHXik1M9wvHdbaEXK0/8XSgHHXITc3idArrHVk5jpuJv/MfYrxcuoXssIuIXcLw89iX0WmOa2X7wT78F9du30Au3AnxDEpO35+PYa5KTOtPAPnILmMcpIjLs4NjottGX7JPC5pC3F8T4gjY5dwO6Pz7cwnnk3iG+vzsmMzElnyygbNTqHDr85RKO12bP9GA/JqPPY98usz9dPmOWmu23OMuVHFyHc4orZ/D9tCgi6ON3XtNF17lSxOPdOED3+bWr6Jf2j7aNNheXMA/apvDaaID3U9nGcxqldM6Ua2zMADQ3J9yPY1zhNKYMUnqP4XfyR2YTHzVkMMBnjbsb+P1VyOP9VK9WoA7IN7Wx20VEZH4W1xOwMzockDNOxwzJS3fJgXUoczeK8DuRM1Mfpt/Z/TWGPOei8j1lZJrS3+mAnA37i8C4b80XPNRx9JdVRVEURVEUZWrRh1VFURRFURRlatGHVUVRFEVRFGVqmSiS+JS35qbobMzZ6D2GDjoaboROyGBkOkar85h9uXYW/bWtHuepod/gk3tpkawW0n7cy7Pov7m0XXDnADNNsyZ6LCIi20foZbWL6NOcCsifOURnVYb4oXZs05/x+IME+zEjz7Y4ND2Tna1NfA25Kn3KeKwHWM89edE45oOk++TSFPDahjb6dD45fL6H+8vboTk2MnL0Urq2CytPQ+0ll6A+2EY5kh3ruEDZgSGOleEQPz9fwH63x9w9tTruWe9XyXWcx/P0yfnrjNDd2hu+B3V5CcdKPkFnNRhhlqaTYB6piEhGRtlu8y2ocx76YDMzT0JtR/gZzOYR3kOvvPsK1PPn0Xv8vX/4DajPXeF8XDMzMeC85BB9sMefxQzcu2+i6/tv//C7UPshuogRub4pufK1PPbh+jJ67IZLJiI9Gl+ci9oK0EXnXxI8D4/Z9fB4Xh3H0v1NzLXe7eLr505hnq2IyPYmeq5xhOPXtvA+7hyjhzuKzXzZj3HYJ+WMR/LnDNfthFrk5H3urRS/L+4PsL7axrn7g6P7UNdm8N5IaT1Bq41jNdrE3G/3eMNo8+/+PjqrB1votZ6v4di089iGV+7inEFLR6Tm40RVyeE1zfl4TS0H/y4iEoSc74zn2R7h/XIQTHZUmR+/9hLUW/fuQO25eFL9Hkqpbh7n+nLZnKPWlnFubjfxGMe0RqFQwPvxuIWvp7haicnJHtLaFEfIY39IV/NBjJhT/ocTnFXm07ZgXM7qw9yXE9ugzqqiKIqiKIryy44+rCqKoiiKoihTiz6sKoqiKIqiKFPLRLGkMEQHajtG12yBvMTGkDySfcxjjLu0ubqIXL6Cvs6pS49A3XznGtTLtM+xkMfl0V7NBcr9c8nSKBbRdbl+awPqub75PH/uDOa1bfro8+zdxPMudJtQW7Tnt5XgOY0czpLFNoR9/HuTsj1FRIpFzLbski/Xp5zU5hbu1+6ewqxY5sras1AnRfR7Eg9dsOU6eoj5GrbPSk0X5uDgHraRztvJX4B6NMLc1GGE4zNfwMzEMMS/D/voJ/f7OHYScpoSyscVEalW0CcrlCk3+ADHwsjBe2ynj85g+Qivk9PA40WdDaiLNnpRjcIZo42uj30dB/ieUg594rUlvCc9IT+TWDq/hscvo/v79HNPQX3hKRxrSYb5o1GC10lEJKR95oVyHv0yTm2nnsBz6H3zL6B2I+znTh/vF9/Fe/DpR89BfeYs1u0+noOISH8fPb9dys/cG1AmqIPjzXHxPi8v4bzxxd/6Ah7vWz+GejtCF/I//P1fM9r4l999FeofvoS5wFvktEbBKagtnp8fwDlhH3KfcmVjWjMRxJypPc51433IKTuZUkcDmneOyCP2aVxVRjQn0BRQHmHm9SjD3Iyp/iAAACAASURBVNUoM938+Bi/L3bv43deTL70C7/yG1DPkUu/UMa5d32W5iT6zszn8P53XfOxgDNB4wDvjzu7+N3/z36wAfXOaPIu9beuoZvfPMR+PHcOM65zdM6jkL4zQ3PO8NzJY8EhH7NLXm5GOcY58mTjPt6fGX1fhCm2MTWG78kZp/wWdkhPqv8m+LTOqs3y7ye97udpjKIoiqIoiqL8TaAPq4qiKIqiKMrUog+riqIoiqIoytSiD6uKoiiKoijK1DJxgVW7jwsAvtdGQTjGdRjyxRQXUhT2MRw8H5kB+5959kWoV9Zx0cy3fvwutilAcTpxsY0RCf6FDAXj0Sa2yZnBxVLnGrgQaJTgohwREbeEQvqTX/oc1E3KxW6+sQ91QGZ16uLipCG1uVSiji5gSPTQNxc1pLMYFj8SfM0uLfRpt1BoP756A+rfpuM/+dTXoLZrKPHbZWxjPY8LiZwcnrMjuChAROT9a69DfXQPF4Hd2cXx5Lk4NgplPGc/IgE+wuvYp0DvOKNFNj62cdAzF7bd3sDw+XIePyNJ8Zbr0cYZB10Mcj8fnYG6uYXj/d7Gh1B7IZ5zvYx9JiKycgYXSrZjHAsphcvPeLToK4fXmqkv4z31X/53/xnUfgH/jxzZ2I82LXywx0xThQK2IcvwPTFtBrJyGhdxXbyMC64238VzzBJ8v+PhYorQxQUeb9/ChUj7LXPe2D3ARVcHbbz2HZq7bAfHYzmP1/75X/ky1J/7zeehfvUdDFYf3MSA+1KdQspF5He+8RWor7//Tajffh0Xwnztd7Afl87gvPMgvofX0bLxmtUohH1AC1GHHR4nJiet7fAdfBdvkOHSAqhTVWzTlUVcxNk8xoVF7S7OSVGK57jfMRfefe8lDMR//LkXoM7lsN8aZbw/1xdxY515WmBVp8WvtoXnWKQ5ynbMng1pU4BWD8/z2n1cvJfQ4lYr/eSFdyIih5u4cU6a0MIgmjcLRbwO+we4CU65YG4K0O3hAm+PFpqORrTgFm9PKdCi5XYbj5fF2EdF+p7uDGmjERrf9tjFUBTyT0uszD0CPt2CqpMWQ9m0qGzc6z/tgqqfdxGY/rKqKIqiKIqiTC36sKooiqIoiqJMLfqwqiiKoiiKokwtE53VsIMeys0j9N+G5PzV19D3fMpDh6PimiHqZ9fXoa6W0XcLEhRHggHWvoceyCijv1NIuk/hwcMm+no2BSKnjulj7B2h93r84QdQF/PoeXTz6M90C+gcBWX07ziMvjiHfdKkwONubAYu2xH6bju76ErZefJpyJ0sdUzn7kEuPPlZqDMPHT52iV0Hz8lJ8PVWwXSaBu/heW3dR5+zOcK6UsZ+jnfJIcrh3xdmFqCeraLL2RtgmzloOhqR1CQivRaGgI8oCNomr7s3Qo+wR6/vpOjpWTZtgmEtQv3BTXRma3OmV3vs4njzSthPPXJ7j45x7JxdfA7qZxf/E6j7Ab6/NIPXOhX8PPZNLXLm4sAMUs8y/n829ktIzlx9Ec/5d/7+b0L9r3b/COpBiz8Tx+eRjddxboHGTmzeP0GEx3BLOA8UaDOQhXm8ts+/cAXqz/8absxh1bFPVs7ivJGm6DLevIlOq4jI7/xd9O8vXVqG+o03MbB+cwMD7U9fWDGO+TElOl+H5tYmOYCDEP+eJDQXjwkTN/w3clBtckgTut+eWUMX8iuPUB8G+Po2fYMmMY6LQRfHQZnmGBGRp57F++m5z38J30POaRjgZ9is/NGaBxYbfVovEEV4P25uoP8pIvKXr78D9es7eI9/2MJ+bYf4/WK7k73EzhDv1yJ9n3RatOEQbQpQpNob82QTjNBDLxexjaMRbQIQ0HoYerbI6FqzupnQP8QJzynsbprj+dP6oJ/29Se936F7LB1zfN4s59OSpub8Pg79ZVVRFEVRFEWZWvRhVVEURVEURZla9GFVURRFURRFmVomOqtfP41Ox0ETnb/X7mDW2p9voJ9TOIfvL5bRlRERqTjoMUVdylG10IfoU85q3sFTSDgjjjyQlByMZh99vGyETpLfx88TEYla5Krcugd1kf4PEFI+27sxujMbh5jDmieFw0/RpfHylFcYmT7QqIUubj9DZ8+lLL7Ew2OcbqC7xRRr6F7FKZ4zx+SJh/2aZjh28mXTWY36mH25dwPd4IyyXOeXHoP65jV0rocWZmVafbwO7ipn2GG9c28D6v4A/VQRkcEAx5NDPo+VoQcreXSxMg+vy/1ddFobNTzn9VNrUAcBnuMwNHMdwwD/rTKDnzkiRzQkfzkn6MXK41jG5HKlhl6KfeKSyxmTF5WNmaayDP8tivE+zWw8h9jDa73+5BmoC0uUofgh5j5aLvbR+vNnof4Pfu/rUO/socspIrK/j9e6SznWsYX3yOoyrgE4dQod65C88OMhOtxrp9G3dG0cO7ev4zmKiJT+Afbbc89g7vVbb2L+8rCP1zqJPtk/63TwfuHXhpwpSXO1P/Hb6qfvoXuWh55j4d8vLGKf/P5XcQ5p0/x/3MZr2KAM1K0e3itPPo6e8fNfwlxxEZHGDGbTFmis5TK8zo0q+pl56hjfxnF0dIjz6PtX0Tv+/qs/hPrl779stPHYxe+DmS9g8vYgxjan9L0tqble5UGGlOPqCL6+eYhz+fwi5iavruC9kc+ZGcLNI8wSPzzA+yVNaI2DjbVPmaMLK9iG3UO89seUqXuys3py3uhJGaW/aGc1IZ/UfghPnB3Wce+Z9P5PQn9ZVRRFURRFUaYWfVhVFEVRFEVRphZ9WFUURVEURVGmlokW0MUV/PN/UTwF9XoOnafvXkNH4zsb6Hw8fdrM4Ovdwqy/Fj0/O+RMtEJ0HeeL6GImGXolUYptOKDcvcMiergjyoKtWGYXlWr4mSllt8oRulm5HHpRm5TndkT5gUvkLRZL2MZKCY+XDU2v9jDEz3Ad7DenifXjGTo+5S72G0P6jmQJ9kFEua1xgm1MfXQI0zGfZ/XQKYp7mPPbmEdvMDjAv/f30feMU3Rjoh5epyN6v5PDkxwOu1Sbzmp3gG12bBo/DvbD2ln8+8IyupMUsWg4Rf0IM3/PnsF71E1WjTYOwvehtl3MVQwT9F5LZfRi08lDQyxysWLKcXRd7FeO2RsMcGywn/rTd0GV0L7cXh7voZD+W16oYxvKK+jk7fbxWtdqeF0WzqNnWDuD92h+5bTR4gsW/ls05MxduifonrJt9p+xD3IODpa5+VmoK+Q6+h7OIyIixQq66E997hGoG9/Efex5LBRyn/yVEpLLllH7XcritBzy8UiDjMf81uKzw0cZ1ItlnOf+3ufOQb1Wx78PyDtcrOPc36A5Yq70AtSXL12GulpDj1hEJAzxuucccv7IWW3uow99dwMd8h+//ibUr72JGak3b92GukvzYCLm+oHG878L9ZBzsslT93jtiJGLjMRD9D1TvrYJ1laG94br4lhaWkafVERkYQ5zi//NrW9DvbKMzycFnEJkQLna/QivU5zi3MznYFNG9sPopSc5qgxnlvL3hfl+Xh8w+Xgn+afjXsM1t+lhPVv9ZVVRFEVRFEWZWvRhVVEURVEURZla9GFVURRFURRFmVomOqsB+aEzefQdXriIOYCHffQb3thCD+XDPdz7WUTkEfI3Q8qMyyiksUteVxagY8QZpBl5JEJ1IYfuTTdDp7BzCj0XEZHZxx6F2iHn7t0/Ra9rndq81pjHN9Bez3nyb9oR9lH/CK/LEnm3IiIrc+ir+eROek28Nqe76Gat1yfnrA5D7KdwiP7OiJzZJMM6jjEHNhbsAxGRQRu9QTuH488t4Tm1DtG9OtwhF5OubZxgP5bruA96PCK3ku6HwRDzC0VERglm5lo+ik+uh+Nvbg0/88JF9HB3j9Cj9VGdFMvGv4d97NelxhNGG8VGNysrY79du4r36TLtUV/KYTYyM6Q93R2H8zLxusVkSg3ofhiOcByIjHOn8BglB++JxGKPCsdCfRkd1NjB62Z76IPOUDZmRH5pKKbYa1O+ssWvISc1JO/boj3fOVPUd8g7r+Ic0JjDc1peNdcQJJTFOnsKP+PUeTxmRoHK7gSnjnOLhbI0rYzzQrGuFfH8At70XkTiGI/pkFe4VsZxcImu+5C8RCvBa1bKY/+cPosesn0OHfGcj+MmoXlRRKR7iN75GzdvQv3+++iYv/UOOqi3bpOD2iUHlfokJXfYocuSnzW/8yrzeF4ZH5NyVDPDe528//upOZxTZmewrjewTR5ll48SvG4HlF0uInJ69TzU66vo98/P4XdeTLmr2+9/CPVhC+elkE7RojnKsnj8f/pM1JP8TtNJZefVeAdVf/UsWJ6bHYdytOPJmbufeNyf612KoiiKoiiK8jeAPqwqiqIoiqIoU4s+rCqKoiiKoihTy0Rn1XJoD3pyrpbr6Ht+4Sxm9HXIa9xoofMnIjKgLL2F9XWoHR/dlVGMzsaoi96IS46S72FmJLZQJN5D77BK7lnQMdvcpD2t6w30nurkx3kjPMYq5aT69H8Gq4Sek0V5iHYP/ZxF13QISS8WO8B+GVC/1SiH9fwpvLZMQpmlrAbnfcwjjII+1GELswKbEe65LSJSnEWH6Ktf/zLU2wN0K+83Mfd3/jz2Y0rXJYnwnENBb7dURadv/z62eRSazuojT1OOYgE75qiNOaz1BRyfYqFXOOxhP8/M41iIM+yDuUUc4fPz5v9HbRtd89YQx898Hd+Tc/Dv+9umd/cgI1YxKasvIj85isjlJLfLH7PPd0L5mSkNwBF5ryMSyiKa+So1dFwdHz0rL4/XKedhHwYDPH5s4zmJiKQBjjc3JSeackQzI68W56bBEI8X2NhPzSbec0NyroslGnsickgue0zzaYlyWPt9mlcGnxzCmyMPmLXGi7S/+/lldPtPz+Cc1Orh+YmItOnf/Bi/gyoR3i/hCNsfBJSzXcGxXyRf2yLFr1TCNh4fozv5F3/xfaPNr7zyI6g/vIq5qYdH1Gb6Hub92yWZ7EY69L3O37HeLLqcIiIWvcZOye2lY3KGbpZN9hTPr+P9VKzg/eiV8Lvg7vYh1Efk6Q765hqIg1Pk86/ieoGDA3SHb29gTvfWLs33Fg7gjOv0pIzTvzrssNr2ZK+dQ61NxZW/1zkbedzvmzzerImlwUN2i/6yqiiKoiiKokwt+rCqKIqiKIqiTC36sKooiqIoiqJMLROd1Yxz/Uiq8lN0Z67M4OEOltE76QemxxXTvvZzs+gp5cvoSLXIA4lCdKRiqgPai90mr6RKj+tsaoadthiM8JjZLnpJayRheA55ULQP8oKD7tgxub25CjqxaYSNjgem79khP46UVUnJIV2+gr7Y2VOUBUuE5ABaNJSslPd2ppzXPPqkedpzW0Sk3Md/695Gh+i5x7CN5x8jCc7GbL5wiG167S/xeIeH6NQVKvj5gyE6rbUZcvBE5MnPYu7inf1r+IIKjo2VU7iHdaOBHlW5hN7sMMZc1e6A9pPPsE2bh+8ZbZyps2+J91itQBmilKEbjMz7+EH6IY73mPJCXY+yk7s4fivk/c3PYraniEjmTd5fmvMyhwPK/aVw5IRyIm0fr1OL9k+/ewc9wsYyjhWngGNFRCSj3MY0wvHapczpEe0Zz+cYRTT3UZ/cI8e6TV6f7Zm/VXR62G47Qw92OMLPuHETPfF255Od1a8++QjU9SIe6/w8ZmeWKA+05uI1ilxzD/thCcd/3Md5LhjQOXNeL/nSRZ/WH9D+7r3Dbay3sY+/86O3oP7n/++fGG0+3EcXkhVU3mM+pe8wO8M+zygr06KMYJ+8W5+zoBcwU/Wjf6RvRnoWSIW9cxIRyX1kSjVal5FDR3WQUB9QdrNr4Tgt5Myx0e3j926f1izc3rgDdbOJ1zLmhRlGRik9LxmZqPbEv4/LUD3Rc6XxSo9s4pLDmpJfmtFgS41cVWwz50mLiCTkJ9u8XoaeDbgND5s3q7+sKoqiKIqiKFOLPqwqiqIoiqIoU4s+rCqKoiiKoihTy0Rn1cil5GC8GF2ZmouywmcoO+2oizlnIiLhHnpVETlGPmUBjtihoNwvO8U2JZQTaNFe1jEdL/TYETEdDYsyHhPak5ulDd6bOSPnNZ+gM5SR47ebR6cvotzJFJUkERHxyN0aDPCYPnkm8+RO5l0z2/JBkpD6gM7JdSljzkUfr1LF65oMTe926x7uxXzjPdwzu5J/FOrRDObkDakfZwuYH2in2Ob5xkWocwX0qALK163RXtIiIlGMn9ntYh7g6hp6tlaCbXjpu5i56BXxMxdOkTfu4MXf3Ub/LUww11VEpNlDD3Ymj45arYzuYOySI81SHdEl79H3cCzlXBybPu2fblvkP1vmNBVShvNggP5ZFBmhpZNKiSgH0snjObda6Kj+ybf/LdTV2d+C+sw59PVFRBIhxzTh3FT0/rgfeU9tj1xDO8V6Zw+vfUjzlpsb0688t5E3y9d++x46m0dHpqv7Mb/32bNQ+zm8Cnd3cOy+8hJmkj5GmcSWZ85RITl8t66hs33hEbzHbZrfW1uYcdo/Rs9xdwfXJ9y4ha+/f4h9HhdxXp1ZxT4QEcnoHk7Y+aaflAKa1+IBZmYX6DvMJl90NMDv2CSP39OFBq5fEDF965ic1Uzoe5Zcy2SM6/ggtTnsp3s7eE48NhI6fjjE44+GZs5qq49zhuXh+A9ozmBF1XXJvaRniZT9T54mOZSXGOes8r+xwuqSu5tyvi2vJSF/OUvw9Q7nrJI3HhsZvubaJoueyXj+trgfrMk+88foL6uKoiiKoijK1KIPq4qiKIqiKMrUog+riqIoiqIoytQy0Vn1ydlz8pjPFrbQT2I/dKWOr3+ijc6IiMiHLcyN3N2+B3VniFlnPRJBRpST55FoEpOvY2d4yn1yNAbkX7hjnufTgNyUgFwYDhrjfctdcmPIRevz63OUa2nj+/OeKa2mCTo7JcrEvbCIuZANHz9zcETZl3R8z0OHKerRvue0t/ooQXdze+8nUF99/V1hKg56f6UIs/4+/N7bUOfOYL8fkUdbPI+O6Zk1HJ+be7TnNrljro+O3OIp07VJM7wn0gG+p2jjtbpz7QbUr/xoE+q1K+RJVWi8x5hBGnfw82bmzVt84w56dlfb6JJ//Ve+DPXSGrqC/dj0YB+kQE51Po+1T/me+QbmvObIlx4OzXmj3WrTa3D8lcm75Yxodlz5Ni/VcGx85rPPQL1xH6/bP/3f/2+ov/qVzxltfvTJdahri+SPZXjPuA6Od4u8wJjG50Eb79mbtzawARx9PGa/9iTFe2gY4jxSKNP469J8OsYV/NmxaO5tkkN4lTzFl9/7AOpN8rdnyzguRURqHp5TlbKSCxUca5s7OC/duItj+42338S/b6Kj2x2Rf+fiNX3xM1eg/q3L54w2kx4teXK4t/bRk93cxzZ3erge4Pr76Olee+MVqNlD9Jcx/zZ1zO+TZEDrTTjrlfxh01md7CUGNBQ3t+mcd8nFZ6GUcr353hARKZbwecaNKWs54gxSrDmXOOM83JR9UcSiG9DmjN8xpOlkZ9UyZHysud8dG6+bRW3wOQvWOSk7doyrSx5sSt67zbmsjuasKoqiKIqiKL/k6MOqoiiKoiiKMrXow6qiKIqiKIoytUx0VoX9Bov2ECZlaGSjx+iRB3lqGT0wEZE7m+g4hbRnfZLi31uUY3lIGV4Vh9ps5JShg9Em72SX8kNty3yed3gDXoLf4VE+7R5lwbbJRetRm1bJga2TG+w00fUSEVmkvZyfXcccu/PrePGKtO99QM4rO6vH0X2owwC9qT4pgXstdFK3j1+C+nDXzFld8h6DepY8qQ5ls3q76Cn6lL23mVyH+tKLp6E+SvF4x9s4tuaXsd+f/Kw5NvK0r/3hIWa7Hhyg+1UqY89evrwGdXUNOzJLaI/7CNu4u4X3T785JkuTHOtWD/3PrcuYu1iqYO7iziH6xoxH49mmsZR3cOxlJ+1XPSbbL5fDfvbJJy6Qb9/tkl+fYL/mi3i8mPI3z1/CsXLxiUWo/+QPcTx/81++bLT56330Xp/7VTxmauO1ijkjmuYizjfc30ffstvD67x++hT93Zw3dmmfepfaVJvF2vZwbPQoJ/tBfriNWbXBCF22nT1sT5G+LpqUJ3pnF71GEZGVCnru3/hd9K+vPPEU1H4B77/ZZfSKFx69BPWvkAu5MIMObL1A/VXAk8jlcZyJiJTo3zzyCHsB9lOTMrN3Wnid/3Ie798heY/bRzhOMnIGB030ckVEKFJUCkXs58x4VjjZdYQ29jknGb8j+Xs4idiNxjmD80dFRBxqA0WBiy+UMZpDd5cziEX4OWBymDP7prbNOa1yIvwei87b4bmXGmFTrrdDxytQlqzr8nWlrH0RiSPOj+YTiaimNjuTn6c+Rn9ZVRRFURRFUaYWfVhVFEVRFEVRphZ9WFUURVEURVGmFn1YVRRFURRFUaaWyQusKGg3oOBtXmjEYfhZiGJtmUJ5RUTmqihKNw9Qmu+SRN8mcfoVWqzUIKm5SovCSmQ5Rza+oRNTIL+YYcasAzscrEuLvIrmO6ByLRSOi9SmNEKpPyTbvTCmjbUyhSJHtLnCMX5mp4r9ZMXYr6jsixz3dqDud3ahToa40KLVwyD6dIQLhWpFU8AftG9CXZqhIGoKfvfyKP1XI1z8YC/iYofGPC5sqNawX+9dwwVXFl235p75f70gxsDuxSVcMHV/C++ho0Psp8zD+2GB1mPkcnTP0XgOaMOKnet43UVESh4e9OLTZ6Hu0YKrw2O8Nl5ucsB3HI6opoUN5OgXi7jgyqOAccc2pymfXsMLOHjxTsoLJxMc73GAf48iWtRyjItSXvjKZaif/9JzUP/wpfeNNt+5ixs+LN3HBRy5Mo7fWm0G6pAWlXQ6OHa6tDHHI1fOQ12v4yLLasNcLNFq43jhEPFTj6xCPRrgPTAIP3mB1XETF1jRXihiJTjn+BZe45A21FiaMeeMtQtPQ33uqc9CXanjgioOZq+W8X5anMUFVj4vkqGAcw5pt2juT8YtNEpwrIUUVm/Topaij2N3sYb3x/PP4VjMlXEzlD/+7negvrd9F5uT4twsIhLTnGE7tNha8FrZJyy4Yka02C8eYhushBcScfg9DqZxC4Eyuqdd3ryHyowWccYZXyf8zMz4nkcSXjhKY+GENWg/fQ0tyqLP5G+kokvPFh6+vlrEe6pY5OtMzyquORfzPZTxPUHdwovfPP/hfjPVX1YVRVEURVGUqUUfVhVFURRFUZSpRR9WFUVRFEVRlKllorOapBzWTT4OuQe+Sx7ZkMJgxzgZCyV8z5vvvgf10TaGVMe0CcABORsd2jSgSK5LkfyJHJ1D5rN7Yz7Ps3/juujvJORsdMjFiilcmB0PQ+EgZzWlNtucbiwiKQXxtnroXzoZHjNno8tlpZN15mEXHVXLwevkVdBbrFHHB7fRH63Mc3CwSDSHAfqWhw7fyszjUG9uYZvaN9C9vLJ6BepyGfttfQ3HztE2fv7tD/D1w47pRTlF9Ab9ArpXiyt4Drub6LgGKTl/vKkFBSpX6+gcnT3fgPrgJm7eICISR+gldZroYu3uoLcYJDh2ZufQgWP6A7yWUcw1jt8wxLFRLLCPNsaRJXfLcXC8JuSoRjQXDXo4/ve20EldpGD1Rg3PeUD+2+kn5qE+HmEtIuK7FPZOOnFkY5v8AtYJ+fRuDu+hxVX0o8+co1BzCrQfs9+JhBGO6XYH76FSGf3iQp7aVMS58EGWa7hmIaLrGlnYx7kS1vewy8WvsUkv8uWvPAv1DG0SEMXsDU7ekIWvWQW/HgxcGpc2zdUcwi4i5oVI6fshPSFgn8p6FefyS+fRSf/g2jLUW1vorMapeb+xu8zupJGHT37mSTpmGuP3xQytoXDJvQzId85SvDCeY45Dn76nfTqnJMW/t8lJzXu0aUce+yAMsY1xRGtPaGyxwzpu4wR2nh3awMF38VrVaFOaRdq0okabVuR9WgdC452fdXieFTGff/g9Fq3BcciDdcZs4DAO/WVVURRFURRFmVr0YVVRFEVRFEWZWvRhVVEURVEURZlaJoqJtocugkdKhcU1+wzkJCX9nvEZyxX0rmY9fI9HeZxV8ndG5PvYVMfkuvTJExmyJkJ+qROf7JHY5Mmye5JZnMWHeJQJ51E/FuicyvRfjJJlOkae8U/4DwHloPKlKdp4XZhh8yrUTg6FsoDO2a+gS7P82ArUUWSeQ5zDE03bmKva2Uc/tNfCeriDY+fd165DPVvFfrY99Ns+/zXsgzNnF6GemSeJTkSqC+gJFmYpt87GrMvDLfTJ9puYLZvm7uEHRORikavlF7G2sDkiIlIpk7eXYsZhj3zOmFzKfB69RabVNnMaHyRJ8H4ZDPHaWyl+XjAyj8fuVC6P/ez7eOK9ATpxEd3XlRn0/F74KrqPp86g52d72MbKDPqYT38W/WgRkaKP46laxfEcCJ4n58ta5JPlyLljMXBEebdRhHNbvmBex0oF+8HPYT86PrYpDPAe4Nc/yLk5PN8kxXHQorl6QJ7wIw30sc8/+5TxGaurp7B9dM6OQ/4nH4D+IeV1GxnlTrKTSr//cPb4OHvzJAeVSTmvk9qYoyDjKmVnXjiFfXTr9m2oN5tmNnPm0jxmTfYUbc5cTyeflEVrLOZncB6bn8XPS8mrtYXG6ZhsZsbsR1oPMMDx6eXwHudzDEbYppC+Hk5yVMc5q5xX63s4vgo+ZdlzbmoB5xz2Qzkj3qb7g/vRtsc56bTuhwew8ZMovf6EsfGJh1EURVEURVGUaUEfVhVFURRFUZSpRR9WFUVRFEVRlKllsrNK+8A6GT3bUj6oGM4qZaWNyZgrW+iFfIVcxjZ5I2/dw1zKQwpcG5H/EJAhmlIbU3pe52xZm8VcMfe6te3JzoVDzinHohbICymSF1Jx8QMrNvb77JirWKRGekIZjtTm+SVYvQAABFlJREFUjPZWHo3xBB9kifLaBrRnvSvoOGXk2/kNPH54jK6ciMhgH+vjDzEL0++hY1oNZqGOye8JMhxLaYI+z/EeOn5d2ov93FnMdQwo/1ZEpHkf22j38CTyJByfPYve3eIqeoTHI3SQDg7QL01D7GeHNi9/6vkzRhudBPdoT4Vc35j25aZrybl5TEr7hHuUwyc0vnt9/LyEZK9+z9xv3qHx1KhTdh85dkIuZZ7yQJfIxSzNocRdqPA8Qfd0isd3G6bbVSLnzaP5NRriedsJXsuYvO5OFzNQA+o3dlxdOkeevkVEcnk6D1q30B9QG21yg7t4Dz3IXAXHdhRie3oDvJ+Kj6M3vE7O66VzY7JsaT63KRuTtkYXj7Rf0j2N9Qmuxd8P9Hrju4HaM+Y7kJ29jNYXUCS2RPQPGR3TETyJUgGv0ZNPXIY6IMfwz37wutHG/TZeV5vzN43QXsra5I5hyNd0eexS7Xl4f3sOu9Jj+pk+g/ObOYeYfc1KFb8vUvo+sYRzt7G2bHLzjWcLs82GC8y18frJ77foOpk5qni/c77uOGfVsthr5ZxV9sT5OfKEsfHxcR/qVYqiKIqiKIry7wB9WFUURVEURVGmFn1YVRRFURRFUaaWyWFkPnlf5D1anAtGDlZMe4KnYz6OXcllivf87adWoV70ULS6uYeZcHt9/MzjmHJZU3QwAjqF2CIfaMwG2raxty25KfR6j5wkihOUEmdG0mfmKLO06qD70nBN56NEeWq8rzG7WZzBOBiT3fogczFmHgbL6JPtb7ao3oM6LqL75oa4h7GIiL2Fbcg3Sd4iX05ibEPpAmX4nqc9ivkz97HNu7exzckxup0LZ8e0mcZXIcB8zmYb/UsvwRzV2UXMcl2awbzOZLQF9f0tbGOhjOfcmDdzL+MR3tcui3yH5H23aQ/3kenqPkhIe2LHNLaGQ6z7fezXnIfOq+Oi6/nRv2GdUVZxEFOucIL3UBTidWBPMEcZvLGFzl5ImYpJQHuX980M3tCh3EZyeQ+b6DfPNDBnNKX59nDnAOpRiMefW8ZM34T8tGYH3eWPICeTOnpnm3xnmtuSMfvK/+zIMfbJiDJaC+SYP3YB80BXGjhuC7b5WUZOJHuBHAFJfcovZ0eQv/MyakLKawHo9XFifp+wOxkl+J4+7TnfG2G/DWnsJRlesyHdCwl5ictrp6GebWwYbTzq3Iea+9UiAdoyPMTJXqJFbi9/p/o+tjmfp/UwdE7sGouYOarc7xn9veihY+3R2Irp/RatJeEt702Xk/zRcX10QkwvP4KZzjQ5p4bUyo1kR5Xfz17umNcY15I+M+PzfrjfTPWXVUVRFEVRFGVq0YdVRVEURVEUZWrRh1VFURRFURRlarHG7UerKIqiKIqiKNOA/rKqKIqiKIqiTC36sKooiqIoiqJMLfqwqiiKoiiKokwt+rCqKIqiKIqiTC36sKooiqIoiqJMLfqwqiiKoiiKokwt/z9wAdwx6SIoPgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x504 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PXf5pEeKlml",
        "colab_type": "text"
      },
      "source": [
        "**DATA PREPROCESSING:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eGKXpfkm1ZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ee29f4d-2df3-4dd5-84ad-0e3c2b277c80"
      },
      "source": [
        "x_train.shape                                 #printing x_train shape        "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lfFrKWy4dhx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64c34c59-ff14-486f-b123-692a10806f92"
      },
      "source": [
        "y_train.shape                                #printing y_train shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRw-6LmnocYf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "871b8159-7830-4ecd-f918-8c94b105bae0"
      },
      "source": [
        "set(y_train.flatten())                        #creates a set of total classes present in y_train, set is used as it can hold unique elements only"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7RbRWRXq3d_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85f288d6-c3ab-4214-c837-e2194d1b01dc"
      },
      "source": [
        "# number of classes\n",
        "n = len(set(y_train.flatten()))              #len function writtens the total number of elements present in the set\n",
        "print(\"number of classes:\", n)                                     "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of classes: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1_i0R8fq7I9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = x_train.astype('float32')/255        #normalizing the x_train and y_train datas\n",
        "X_test = x_test.astype('float32')/255"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxA6-AOknMgG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "abb12bdf-72e4-4981-f9dd-4a0d557430ec"
      },
      "source": [
        "Y_train = to_categorical(y_train, 10)          #to_categorical performs one_hot encoding\n",
        "Y_test = to_categorical(y_test, 10)         \n",
        "print(\"X_train.shape:\", X_train.shape)         #printing the shape of x_train and y_train\n",
        "print(\"Y_train.shape\", y_train.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train.shape: (50000, 32, 32, 3)\n",
            "Y_train.shape (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF5YpvIKKyLq",
        "colab_type": "text"
      },
      "source": [
        "**MODEL BUILDING:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwkdLypKqZz9",
        "colab_type": "text"
      },
      "source": [
        "**COMMON CODING TERMS USED:**<br/>\n",
        "1.**Seqential()** - creates an linear stack of layers;<br/>\n",
        "2.**Conv2D** - creates an 2D convolutional layer and creates a convolution kernel that is convolved with the layer to produce a tensor of outputs. Convolution Layers uses Convolution filters to build feature maps;<br/>\n",
        "3.**Activation function** - Exponential Linear Unit (elu) type activation function is used to introduce non-linearity;<br/>\n",
        "4.**Kernel_initializer** - 'he_uniform' is used as the kernel_initializer which defines the initial weights of the layers;<br/>\n",
        "5.**Kernel_regularizer** - 'L2' class kernel_regularizer is used with decay of 1e-4 and it applies a penalty on layer's parameters during optimization. These penalities are summed into the loss function that the network optimizes;<br/>\n",
        "6.**Padding** - padding ='same' results with the ouput  having same height/width dimensions as the input;<br/>\n",
        "7.**input_shape** - it takes a input image of size 32 x 32 x 3;<br/>\n",
        "8.**MaxPooling** - it calculates the largest value in each feature maps generated by the convolution filters and it helps in dimensionality reduction;<br/>\n",
        "9.**BatchNormalization** - it normalizes the output using the mean and standard deviation of input:<br/>\n",
        "10.**Dropout** - it is a technique used to ignore the selected neurons randomly during training and it prevents the Neural Networks from overfitting;<br/>\n",
        "11.**Flatten** - Flattening is converting the data into a 1D array for inputting it to the next layer, flaten is a function that converts the pooled feature map to a single column which is to be passed tothe fully connected layer;<br/>\n",
        "12.**Dense** - it adds a fully connected layer to thr Neural Network;<br/>\n",
        "13.**Softmax** - it is the activation function used in the output layer to produce the output for multi-classification problems, in this problems it classifies the input into 10 output classes;<br/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTvWN8FFq9rr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#building a CNN model;\n",
        "\n",
        "#creating a sequential type layers;\n",
        "model = Sequential()\n",
        "\n",
        "#CNN layers;\n",
        "model.add(Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l2(1e-4), padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l2(1e-4), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l2(1e-4), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l2(1e-4), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l2(1e-4), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l2(1e-4), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l2(1e-4), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l2(1e-4), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "#flattening the output of convolution layers;\n",
        "model.add(Flatten())\n",
        "\n",
        "#adding a hidden layers to the model\n",
        "model.add(Dense(512, activation='elu', kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(512, activation='elu', kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "#adding a output layer\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GtPrNNmOWa8",
        "colab_type": "text"
      },
      "source": [
        "Thus, a CNN model with one input layer, eight convolution layers, six max pooling layers, six dropout layers, two hidden layers and one output layer is created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0mnZYgcrU61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61bbf179-011e-48b7-80d5-fd62163b3bc8"
      },
      "source": [
        "model.summary()               #it prints the summary of the model which consists of all layers added to model in sequential order"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 4, 4, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,972,778\n",
            "Trainable params: 1,968,810\n",
            "Non-trainable params: 3,968\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-kngK_NLDPZ",
        "colab_type": "text"
      },
      "source": [
        "**COMPILING THE MODEL:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bmZpPkHES-J",
        "colab_type": "text"
      },
      "source": [
        "**COMMON CODING TERMS USED**:<br/>\n",
        "1.**Optimizers** - Adam is used as an optimizer, it is a stochastic gradient descent method that is based on adaptive estimation of first and second-order moments.<br/>\n",
        "2.**lr - it stands for learning rate that determines the step size at each iteration while moving toward a minimum of a loss function;<br/>\n",
        "3.Decay** - it causes the learning rates to decay;<br/>\n",
        "4.**categorical_crossentropy** - it is used as a loss function for multi class classification problems and it quantifies the difference between probability distributions;<br/>\n",
        "5.**metrics** - it is a function used to judge the performance of the model, here accuracy is used as a metric;<br/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7tyrC18BIzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = optimizers.Adam(lr = 0.001, decay = 1e-5)             # compiling the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyYZcNPBLWTR",
        "colab_type": "text"
      },
      "source": [
        "**MONITORING THE MODEL PERFORMANCE:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh_qdlFDZzR-",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1. **ReduceLROnPlateau** - it is a **callback** which **monitors** a quantity such as loss, accuracy, val_loss or val_accuracy and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced; **Mode**='max' reduces the learning rate, when the quantity monitored has stopped increasing;  **min_lr** is the lower bound of the learning rate; **patience:** number of epochs with no improvement after which learning rate will be reduced;\n",
        "2. **EarlyStopping** - it is a callback which monitors a quantity such as loss, accuracy, val_loss or val_accuracy and if no improvement is seen for a 'patience' number of epochs, the training will be ended;\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmQA4psrrcnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rlr = ReduceLROnPlateau(monitor='val_accuracy', mode ='max', factor=0.5, min_lr=1e-7, verbose = 1, patience=10) #rlr-reduce learning rate and es-early stopping\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose = 1, patience=50)   #initializing call backs"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdGK2mMlD0sC",
        "colab_type": "text"
      },
      "source": [
        "**VISUALIZING THE MODEL PERFORMANCE THROUGH CALL BACKS:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6NKTZVBEAZb",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   TensorBoard is a tool for providing the measurements and visualizations needed during the machine learning workflow. It enables tracking experiment metrics like loss and accuracy, visualizing the model graph, projecting embeddings to a lower dimensional space.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSdk5RuLLdPb",
        "colab_type": "text"
      },
      "source": [
        "**FITTING THE MODEL ON TRAIN DATASETS:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02VZFu7fP4AF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ba6ac6a3-5053-41f4-9069-c2e686785652"
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size = 64,                    #fitting the model with train datasets and callbacks\n",
        "                                 validation_split=0.1, \n",
        "                                 epochs = 400, verbose = 1,\n",
        "                                 callbacks = [rlr, es,tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "  1/704 [..............................] - ETA: 0s - loss: 4.0001 - accuracy: 0.1250WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "  2/704 [..............................] - ETA: 55s - loss: 3.7068 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0390s vs `on_train_batch_end` time: 0.1185s). Check your callbacks.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 1.9530 - accuracy: 0.4075 - val_loss: 1.6054 - val_accuracy: 0.5362\n",
            "Epoch 2/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 1.3526 - accuracy: 0.5920 - val_loss: 1.2044 - val_accuracy: 0.6652\n",
            "Epoch 3/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 1.1505 - accuracy: 0.6662 - val_loss: 1.0033 - val_accuracy: 0.7294\n",
            "Epoch 4/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 1.0371 - accuracy: 0.7136 - val_loss: 0.8819 - val_accuracy: 0.7680\n",
            "Epoch 5/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.9595 - accuracy: 0.7432 - val_loss: 0.8305 - val_accuracy: 0.7852\n",
            "Epoch 6/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.9092 - accuracy: 0.7655 - val_loss: 0.8604 - val_accuracy: 0.7832\n",
            "Epoch 7/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.8658 - accuracy: 0.7843 - val_loss: 0.8166 - val_accuracy: 0.8058\n",
            "Epoch 8/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.8342 - accuracy: 0.7991 - val_loss: 0.7985 - val_accuracy: 0.8140\n",
            "Epoch 9/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.8138 - accuracy: 0.8115 - val_loss: 0.8146 - val_accuracy: 0.8100\n",
            "Epoch 10/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.7849 - accuracy: 0.8233 - val_loss: 0.8261 - val_accuracy: 0.8240\n",
            "Epoch 11/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.7743 - accuracy: 0.8307 - val_loss: 0.8015 - val_accuracy: 0.8252\n",
            "Epoch 12/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.7602 - accuracy: 0.8408 - val_loss: 0.7641 - val_accuracy: 0.8428\n",
            "Epoch 13/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.7474 - accuracy: 0.8463 - val_loss: 0.8316 - val_accuracy: 0.8212\n",
            "Epoch 14/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.7401 - accuracy: 0.8523 - val_loss: 0.8252 - val_accuracy: 0.8264\n",
            "Epoch 15/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.7253 - accuracy: 0.8596 - val_loss: 0.8099 - val_accuracy: 0.8386\n",
            "Epoch 16/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.7165 - accuracy: 0.8630 - val_loss: 0.7841 - val_accuracy: 0.8444\n",
            "Epoch 17/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.7099 - accuracy: 0.8682 - val_loss: 0.8039 - val_accuracy: 0.8448\n",
            "Epoch 18/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.6935 - accuracy: 0.8739 - val_loss: 0.7754 - val_accuracy: 0.8546\n",
            "Epoch 19/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.6965 - accuracy: 0.8763 - val_loss: 0.7995 - val_accuracy: 0.8512\n",
            "Epoch 20/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.6802 - accuracy: 0.8811 - val_loss: 0.8133 - val_accuracy: 0.8486\n",
            "Epoch 21/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.6790 - accuracy: 0.8840 - val_loss: 0.7871 - val_accuracy: 0.8568\n",
            "Epoch 22/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.6704 - accuracy: 0.8870 - val_loss: 0.8179 - val_accuracy: 0.8492\n",
            "Epoch 23/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.6699 - accuracy: 0.8882 - val_loss: 0.8010 - val_accuracy: 0.8562\n",
            "Epoch 24/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.6610 - accuracy: 0.8923 - val_loss: 0.7890 - val_accuracy: 0.8584\n",
            "Epoch 25/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.6577 - accuracy: 0.8940 - val_loss: 0.7986 - val_accuracy: 0.8538\n",
            "Epoch 26/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.6596 - accuracy: 0.8947 - val_loss: 0.7892 - val_accuracy: 0.8582\n",
            "Epoch 27/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.6443 - accuracy: 0.8992 - val_loss: 0.7791 - val_accuracy: 0.8608\n",
            "Epoch 28/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.6408 - accuracy: 0.8994 - val_loss: 0.7850 - val_accuracy: 0.8650\n",
            "Epoch 29/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.6322 - accuracy: 0.9028 - val_loss: 0.8762 - val_accuracy: 0.8442\n",
            "Epoch 30/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.6273 - accuracy: 0.9048 - val_loss: 0.8183 - val_accuracy: 0.8568\n",
            "Epoch 31/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.6323 - accuracy: 0.9050 - val_loss: 0.8093 - val_accuracy: 0.8580\n",
            "Epoch 32/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.6202 - accuracy: 0.9074 - val_loss: 0.7756 - val_accuracy: 0.8656\n",
            "Epoch 33/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.6222 - accuracy: 0.9067 - val_loss: 0.7863 - val_accuracy: 0.8670\n",
            "Epoch 34/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.6096 - accuracy: 0.9105 - val_loss: 0.7767 - val_accuracy: 0.8690\n",
            "Epoch 35/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.6047 - accuracy: 0.9125 - val_loss: 0.8104 - val_accuracy: 0.8588\n",
            "Epoch 36/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.6012 - accuracy: 0.9137 - val_loss: 0.7773 - val_accuracy: 0.8682\n",
            "Epoch 37/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.6022 - accuracy: 0.9148 - val_loss: 0.8039 - val_accuracy: 0.8622\n",
            "Epoch 38/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.5955 - accuracy: 0.9175 - val_loss: 0.8400 - val_accuracy: 0.8524\n",
            "Epoch 39/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.5932 - accuracy: 0.9158 - val_loss: 0.8104 - val_accuracy: 0.8600\n",
            "Epoch 40/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.5910 - accuracy: 0.9165 - val_loss: 0.8290 - val_accuracy: 0.8500\n",
            "Epoch 41/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.5818 - accuracy: 0.9186 - val_loss: 0.8444 - val_accuracy: 0.8472\n",
            "Epoch 42/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.5840 - accuracy: 0.9181 - val_loss: 0.7728 - val_accuracy: 0.8702\n",
            "Epoch 43/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.5725 - accuracy: 0.9221 - val_loss: 0.7903 - val_accuracy: 0.8644\n",
            "Epoch 44/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.5726 - accuracy: 0.9213 - val_loss: 0.7801 - val_accuracy: 0.8692\n",
            "Epoch 45/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.5710 - accuracy: 0.9224 - val_loss: 0.7814 - val_accuracy: 0.8694\n",
            "Epoch 46/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.5662 - accuracy: 0.9234 - val_loss: 0.8028 - val_accuracy: 0.8624\n",
            "Epoch 47/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.5695 - accuracy: 0.9216 - val_loss: 0.8111 - val_accuracy: 0.8554\n",
            "Epoch 48/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.5607 - accuracy: 0.9269 - val_loss: 0.8126 - val_accuracy: 0.8660\n",
            "Epoch 49/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.5546 - accuracy: 0.9272 - val_loss: 0.8021 - val_accuracy: 0.8612\n",
            "Epoch 50/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.5514 - accuracy: 0.9267 - val_loss: 0.8236 - val_accuracy: 0.8574\n",
            "Epoch 51/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.5502 - accuracy: 0.9268 - val_loss: 0.7828 - val_accuracy: 0.8688\n",
            "Epoch 52/400\n",
            "703/704 [============================>.] - ETA: 0s - loss: 0.5508 - accuracy: 0.9287\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.5509 - accuracy: 0.9287 - val_loss: 0.7779 - val_accuracy: 0.8666\n",
            "Epoch 53/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.4890 - accuracy: 0.9465 - val_loss: 0.7546 - val_accuracy: 0.8768\n",
            "Epoch 54/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.4526 - accuracy: 0.9550 - val_loss: 0.7817 - val_accuracy: 0.8764\n",
            "Epoch 55/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.4428 - accuracy: 0.9556 - val_loss: 0.7720 - val_accuracy: 0.8744\n",
            "Epoch 56/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.4286 - accuracy: 0.9577 - val_loss: 0.7681 - val_accuracy: 0.8768\n",
            "Epoch 57/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.4168 - accuracy: 0.9585 - val_loss: 0.7411 - val_accuracy: 0.8814\n",
            "Epoch 58/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.4144 - accuracy: 0.9585 - val_loss: 0.7466 - val_accuracy: 0.8788\n",
            "Epoch 59/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.4064 - accuracy: 0.9593 - val_loss: 0.7489 - val_accuracy: 0.8800\n",
            "Epoch 60/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.3967 - accuracy: 0.9609 - val_loss: 0.7390 - val_accuracy: 0.8794\n",
            "Epoch 61/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.3855 - accuracy: 0.9629 - val_loss: 0.7323 - val_accuracy: 0.8788\n",
            "Epoch 62/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.3774 - accuracy: 0.9636 - val_loss: 0.7402 - val_accuracy: 0.8810\n",
            "Epoch 63/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.3797 - accuracy: 0.9608 - val_loss: 0.7166 - val_accuracy: 0.8774\n",
            "Epoch 64/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.3718 - accuracy: 0.9631 - val_loss: 0.7137 - val_accuracy: 0.8832\n",
            "Epoch 65/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.3738 - accuracy: 0.9616 - val_loss: 0.7194 - val_accuracy: 0.8830\n",
            "Epoch 66/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.3671 - accuracy: 0.9628 - val_loss: 0.7086 - val_accuracy: 0.8816\n",
            "Epoch 67/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.3663 - accuracy: 0.9617 - val_loss: 0.6981 - val_accuracy: 0.8848\n",
            "Epoch 68/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.3578 - accuracy: 0.9639 - val_loss: 0.7138 - val_accuracy: 0.8780\n",
            "Epoch 69/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.3487 - accuracy: 0.9655 - val_loss: 0.7255 - val_accuracy: 0.8806\n",
            "Epoch 70/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.3457 - accuracy: 0.9671 - val_loss: 0.7174 - val_accuracy: 0.8794\n",
            "Epoch 71/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.3460 - accuracy: 0.9656 - val_loss: 0.7268 - val_accuracy: 0.8816\n",
            "Epoch 72/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.3441 - accuracy: 0.9646 - val_loss: 0.6961 - val_accuracy: 0.8846\n",
            "Epoch 73/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.3419 - accuracy: 0.9651 - val_loss: 0.7188 - val_accuracy: 0.8786\n",
            "Epoch 74/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.3335 - accuracy: 0.9674 - val_loss: 0.7143 - val_accuracy: 0.8824\n",
            "Epoch 75/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.3318 - accuracy: 0.9667 - val_loss: 0.7027 - val_accuracy: 0.8842\n",
            "Epoch 76/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.3342 - accuracy: 0.9653 - val_loss: 0.7064 - val_accuracy: 0.8828\n",
            "Epoch 77/400\n",
            "703/704 [============================>.] - ETA: 0s - loss: 0.3288 - accuracy: 0.9669\n",
            "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.3288 - accuracy: 0.9670 - val_loss: 0.7141 - val_accuracy: 0.8776\n",
            "Epoch 78/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.3074 - accuracy: 0.9735 - val_loss: 0.6764 - val_accuracy: 0.8936\n",
            "Epoch 79/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2940 - accuracy: 0.9776 - val_loss: 0.6893 - val_accuracy: 0.8888\n",
            "Epoch 80/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2869 - accuracy: 0.9782 - val_loss: 0.6895 - val_accuracy: 0.8898\n",
            "Epoch 81/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2800 - accuracy: 0.9799 - val_loss: 0.6912 - val_accuracy: 0.8892\n",
            "Epoch 82/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2752 - accuracy: 0.9805 - val_loss: 0.6895 - val_accuracy: 0.8894\n",
            "Epoch 83/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2734 - accuracy: 0.9800 - val_loss: 0.7105 - val_accuracy: 0.8940\n",
            "Epoch 84/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2685 - accuracy: 0.9805 - val_loss: 0.6950 - val_accuracy: 0.8880\n",
            "Epoch 85/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2674 - accuracy: 0.9810 - val_loss: 0.7045 - val_accuracy: 0.8896\n",
            "Epoch 86/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2647 - accuracy: 0.9798 - val_loss: 0.6992 - val_accuracy: 0.8904\n",
            "Epoch 87/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2568 - accuracy: 0.9826 - val_loss: 0.6939 - val_accuracy: 0.8906\n",
            "Epoch 88/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2551 - accuracy: 0.9821 - val_loss: 0.7060 - val_accuracy: 0.8884\n",
            "Epoch 89/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2567 - accuracy: 0.9812 - val_loss: 0.6937 - val_accuracy: 0.8906\n",
            "Epoch 90/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2531 - accuracy: 0.9820 - val_loss: 0.6792 - val_accuracy: 0.8908\n",
            "Epoch 91/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2479 - accuracy: 0.9826 - val_loss: 0.6914 - val_accuracy: 0.8916\n",
            "Epoch 92/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2490 - accuracy: 0.9811 - val_loss: 0.6818 - val_accuracy: 0.8908\n",
            "Epoch 93/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2415 - accuracy: 0.9833 - val_loss: 0.6776 - val_accuracy: 0.8946\n",
            "Epoch 94/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2405 - accuracy: 0.9828 - val_loss: 0.7101 - val_accuracy: 0.8856\n",
            "Epoch 95/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2363 - accuracy: 0.9835 - val_loss: 0.6946 - val_accuracy: 0.8880\n",
            "Epoch 96/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2356 - accuracy: 0.9830 - val_loss: 0.6867 - val_accuracy: 0.8904\n",
            "Epoch 97/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2362 - accuracy: 0.9829 - val_loss: 0.6981 - val_accuracy: 0.8890\n",
            "Epoch 98/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2339 - accuracy: 0.9826 - val_loss: 0.6841 - val_accuracy: 0.8876\n",
            "Epoch 99/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2326 - accuracy: 0.9830 - val_loss: 0.6912 - val_accuracy: 0.8904\n",
            "Epoch 100/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2270 - accuracy: 0.9843 - val_loss: 0.6849 - val_accuracy: 0.8890\n",
            "Epoch 101/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2257 - accuracy: 0.9846 - val_loss: 0.6937 - val_accuracy: 0.8882\n",
            "Epoch 102/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2246 - accuracy: 0.9838 - val_loss: 0.6941 - val_accuracy: 0.8884\n",
            "Epoch 103/400\n",
            "703/704 [============================>.] - ETA: 0s - loss: 0.2276 - accuracy: 0.9824\n",
            "Epoch 00103: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.2280 - accuracy: 0.9823 - val_loss: 0.6941 - val_accuracy: 0.8894\n",
            "Epoch 104/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2192 - accuracy: 0.9846 - val_loss: 0.6762 - val_accuracy: 0.8936\n",
            "Epoch 105/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2143 - accuracy: 0.9870 - val_loss: 0.6814 - val_accuracy: 0.8916\n",
            "Epoch 106/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2100 - accuracy: 0.9875 - val_loss: 0.6768 - val_accuracy: 0.8942\n",
            "Epoch 107/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2070 - accuracy: 0.9878 - val_loss: 0.6797 - val_accuracy: 0.8922\n",
            "Epoch 108/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2057 - accuracy: 0.9883 - val_loss: 0.6744 - val_accuracy: 0.8934\n",
            "Epoch 109/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2032 - accuracy: 0.9886 - val_loss: 0.6683 - val_accuracy: 0.8962\n",
            "Epoch 110/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.2007 - accuracy: 0.9887 - val_loss: 0.6828 - val_accuracy: 0.8918\n",
            "Epoch 111/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1990 - accuracy: 0.9890 - val_loss: 0.6713 - val_accuracy: 0.8950\n",
            "Epoch 112/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1981 - accuracy: 0.9896 - val_loss: 0.6655 - val_accuracy: 0.8946\n",
            "Epoch 113/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1960 - accuracy: 0.9896 - val_loss: 0.6827 - val_accuracy: 0.8920\n",
            "Epoch 114/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1959 - accuracy: 0.9890 - val_loss: 0.6723 - val_accuracy: 0.8976\n",
            "Epoch 115/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1918 - accuracy: 0.9900 - val_loss: 0.6759 - val_accuracy: 0.8976\n",
            "Epoch 116/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1916 - accuracy: 0.9896 - val_loss: 0.6719 - val_accuracy: 0.8960\n",
            "Epoch 117/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1900 - accuracy: 0.9897 - val_loss: 0.6816 - val_accuracy: 0.8954\n",
            "Epoch 118/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1870 - accuracy: 0.9906 - val_loss: 0.6807 - val_accuracy: 0.8938\n",
            "Epoch 119/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1867 - accuracy: 0.9903 - val_loss: 0.6869 - val_accuracy: 0.8982\n",
            "Epoch 120/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1868 - accuracy: 0.9900 - val_loss: 0.6916 - val_accuracy: 0.8902\n",
            "Epoch 121/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1836 - accuracy: 0.9908 - val_loss: 0.6889 - val_accuracy: 0.8922\n",
            "Epoch 122/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1854 - accuracy: 0.9899 - val_loss: 0.6793 - val_accuracy: 0.8950\n",
            "Epoch 123/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1824 - accuracy: 0.9902 - val_loss: 0.6821 - val_accuracy: 0.8958\n",
            "Epoch 124/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1822 - accuracy: 0.9909 - val_loss: 0.6853 - val_accuracy: 0.8944\n",
            "Epoch 125/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1800 - accuracy: 0.9907 - val_loss: 0.6862 - val_accuracy: 0.8954\n",
            "Epoch 126/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1826 - accuracy: 0.9898 - val_loss: 0.6867 - val_accuracy: 0.8924\n",
            "Epoch 127/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1782 - accuracy: 0.9908 - val_loss: 0.6758 - val_accuracy: 0.8954\n",
            "Epoch 128/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1791 - accuracy: 0.9902 - val_loss: 0.6783 - val_accuracy: 0.8964\n",
            "Epoch 129/400\n",
            "704/704 [==============================] - ETA: 0s - loss: 0.1756 - accuracy: 0.9908\n",
            "Epoch 00129: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1756 - accuracy: 0.9908 - val_loss: 0.6777 - val_accuracy: 0.8944\n",
            "Epoch 130/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1747 - accuracy: 0.9908 - val_loss: 0.6820 - val_accuracy: 0.8924\n",
            "Epoch 131/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1727 - accuracy: 0.9915 - val_loss: 0.6766 - val_accuracy: 0.8946\n",
            "Epoch 132/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1697 - accuracy: 0.9923 - val_loss: 0.6755 - val_accuracy: 0.8948\n",
            "Epoch 133/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1697 - accuracy: 0.9923 - val_loss: 0.6780 - val_accuracy: 0.8960\n",
            "Epoch 134/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1678 - accuracy: 0.9927 - val_loss: 0.6858 - val_accuracy: 0.8944\n",
            "Epoch 135/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1693 - accuracy: 0.9922 - val_loss: 0.6881 - val_accuracy: 0.8964\n",
            "Epoch 136/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1676 - accuracy: 0.9929 - val_loss: 0.6897 - val_accuracy: 0.8980\n",
            "Epoch 137/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1665 - accuracy: 0.9928 - val_loss: 0.6871 - val_accuracy: 0.8958\n",
            "Epoch 138/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1659 - accuracy: 0.9921 - val_loss: 0.6825 - val_accuracy: 0.8956\n",
            "Epoch 139/400\n",
            "704/704 [==============================] - ETA: 0s - loss: 0.1652 - accuracy: 0.9930\n",
            "Epoch 00139: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1652 - accuracy: 0.9930 - val_loss: 0.6911 - val_accuracy: 0.8956\n",
            "Epoch 140/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1641 - accuracy: 0.9931 - val_loss: 0.6896 - val_accuracy: 0.8946\n",
            "Epoch 141/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1641 - accuracy: 0.9932 - val_loss: 0.6872 - val_accuracy: 0.8942\n",
            "Epoch 142/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1618 - accuracy: 0.9936 - val_loss: 0.6869 - val_accuracy: 0.8970\n",
            "Epoch 143/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1622 - accuracy: 0.9935 - val_loss: 0.6860 - val_accuracy: 0.8972\n",
            "Epoch 144/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1624 - accuracy: 0.9934 - val_loss: 0.6891 - val_accuracy: 0.8974\n",
            "Epoch 145/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1618 - accuracy: 0.9936 - val_loss: 0.6826 - val_accuracy: 0.8978\n",
            "Epoch 146/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1619 - accuracy: 0.9932 - val_loss: 0.6862 - val_accuracy: 0.8980\n",
            "Epoch 147/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1601 - accuracy: 0.9939 - val_loss: 0.6887 - val_accuracy: 0.8970\n",
            "Epoch 148/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1619 - accuracy: 0.9932 - val_loss: 0.6864 - val_accuracy: 0.8972\n",
            "Epoch 149/400\n",
            "704/704 [==============================] - ETA: 0s - loss: 0.1596 - accuracy: 0.9936\n",
            "Epoch 00149: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1596 - accuracy: 0.9936 - val_loss: 0.6830 - val_accuracy: 0.8982\n",
            "Epoch 150/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1581 - accuracy: 0.9944 - val_loss: 0.6856 - val_accuracy: 0.8966\n",
            "Epoch 151/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1587 - accuracy: 0.9942 - val_loss: 0.6870 - val_accuracy: 0.8968\n",
            "Epoch 152/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1585 - accuracy: 0.9942 - val_loss: 0.6875 - val_accuracy: 0.8964\n",
            "Epoch 153/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1583 - accuracy: 0.9940 - val_loss: 0.6857 - val_accuracy: 0.8980\n",
            "Epoch 154/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1578 - accuracy: 0.9946 - val_loss: 0.6875 - val_accuracy: 0.8964\n",
            "Epoch 155/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1583 - accuracy: 0.9940 - val_loss: 0.6843 - val_accuracy: 0.8956\n",
            "Epoch 156/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1569 - accuracy: 0.9942 - val_loss: 0.6848 - val_accuracy: 0.8964\n",
            "Epoch 157/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1565 - accuracy: 0.9946 - val_loss: 0.6845 - val_accuracy: 0.8948\n",
            "Epoch 158/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1567 - accuracy: 0.9944 - val_loss: 0.6851 - val_accuracy: 0.8960\n",
            "Epoch 159/400\n",
            "703/704 [============================>.] - ETA: 0s - loss: 0.1566 - accuracy: 0.9944\n",
            "Epoch 00159: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1566 - accuracy: 0.9944 - val_loss: 0.6835 - val_accuracy: 0.8962\n",
            "Epoch 160/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1569 - accuracy: 0.9944 - val_loss: 0.6837 - val_accuracy: 0.8962\n",
            "Epoch 161/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1575 - accuracy: 0.9940 - val_loss: 0.6833 - val_accuracy: 0.8956\n",
            "Epoch 162/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1557 - accuracy: 0.9946 - val_loss: 0.6868 - val_accuracy: 0.8956\n",
            "Epoch 163/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1565 - accuracy: 0.9943 - val_loss: 0.6867 - val_accuracy: 0.8956\n",
            "Epoch 164/400\n",
            "704/704 [==============================] - 30s 42ms/step - loss: 0.1561 - accuracy: 0.9944 - val_loss: 0.6889 - val_accuracy: 0.8954\n",
            "Epoch 165/400\n",
            "704/704 [==============================] - 30s 43ms/step - loss: 0.1549 - accuracy: 0.9944 - val_loss: 0.6876 - val_accuracy: 0.8946\n",
            "Epoch 166/400\n",
            "525/704 [=====================>........] - ETA: 7s - loss: 0.1561 - accuracy: 0.9948Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UruxED1tLlyq",
        "colab_type": "text"
      },
      "source": [
        "**PREDICTING THE TEST DATAS USING THE MODEL:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aXeDc3-rnqK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "62e6ebb0-0143-4176-98c5-44ecaebe4331"
      },
      "source": [
        "y_pred=model.predict(X_test)                         #predicting the x_test datas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.3483273e-06, 2.0746550e-06, 1.9876861e-06, ..., 2.9115579e-09,\n",
              "        2.7325663e-11, 5.2698379e-09],\n",
              "       [3.7114231e-10, 4.8354587e-10, 3.2579791e-14, ..., 6.2576046e-15,\n",
              "        1.0000000e+00, 5.1652158e-11],\n",
              "       [7.1625184e-10, 5.0772604e-04, 2.2198532e-09, ..., 8.7734708e-07,\n",
              "        9.9949121e-01, 1.3873549e-07],\n",
              "       ...,\n",
              "       [5.3836757e-10, 1.6033089e-10, 1.5325679e-06, ..., 2.4745714e-07,\n",
              "        2.9401076e-10, 3.0812472e-10],\n",
              "       [1.7382065e-06, 9.9998236e-01, 3.7363911e-08, ..., 3.0619940e-10,\n",
              "        1.0751870e-10, 3.7417665e-09],\n",
              "       [4.2883207e-11, 1.2592205e-10, 4.8096553e-12, ..., 9.9999869e-01,\n",
              "        2.1020087e-12, 5.0500511e-12]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJaXr5YlLxC-",
        "colab_type": "text"
      },
      "source": [
        "**EVALUATING THE MODEL PERFORMANCE ON TEST DATASETS:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF3Ibm66r2nC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "40f2f5fd-bfd4-4a52-d5c8-da32c706698f"
      },
      "source": [
        "model.evaluate(X_test,Y_test)                 #evaluating the loss and accuracy of actual and predicted values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 11ms/step - loss: 0.6836 - accuracy: 0.8930\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6835514307022095, 0.8930000066757202]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLLCqI2bEtKZ",
        "colab_type": "text"
      },
      "source": [
        "**BUILDING A CNN MODEL ON TOP OF BUILT-IN VGG19 MODEL:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx457f14B9Fo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "outputId": "88a279af-05a0-429c-e088-255f5a44ff49"
      },
      "source": [
        "INPUT_SHAPE = (32, 32, 3)                # defining input shape\n",
        "\n",
        "vgg_layers = tf.keras.applications.vgg19.VGG19(weights='imagenet', include_top=False,    \n",
        "                                               input_shape=INPUT_SHAPE)    #importing VGG19model\n",
        "\n",
        "vgg_layers.summary()                     #printing the summary of VGG19 model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "=================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 20,024,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmVmMnAbB9CC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "35605daf-2802-4728-f817-e0a0a7cea0cb"
      },
      "source": [
        "# defining sequential model\n",
        "model_1 = tf.keras.models.Sequential()\n",
        "                                         \n",
        "# adding the vgg convolutional base model\n",
        "model_1.add(vgg_layers)\n",
        "\n",
        "# adding flatten layer\n",
        "model_1.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# adding dense layers with some dropout\n",
        "model_1.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model_1.add(tf.keras.layers.Dropout(rate=0.3))\n",
        "model_1.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model_1.add(tf.keras.layers.Dropout(rate=0.3))\n",
        "\n",
        "# adding output layer\n",
        "model_1.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "model_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5), \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# view model layers\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Functional)           (None, 1, 1, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 20,224,074\n",
            "Trainable params: 20,224,074\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgfbOzhaIlzK",
        "colab_type": "text"
      },
      "source": [
        "NOTE:<br/>\n",
        "*   model=tf.kears.models.sequential() can also be initialized as model=sequential() as we imported all the necessary packages earlier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgPCB89yJQIx",
        "colab_type": "text"
      },
      "source": [
        "**COMPILING THE MODEL:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jLQ9rF6B89A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "384f8624-20ce-4cb6-a07e-be3a6d09d77e"
      },
      "source": [
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, \n",
        "                                               restore_best_weights=True,\n",
        "                                               verbose=1)\n",
        "\n",
        "vgg_tuned = model_1.fit(X_train, Y_train,\n",
        "                    batch_size=32,\n",
        "                    callbacks=[es_callback], \n",
        "                    validation_split=0.1, epochs=100,\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 1.1492 - accuracy: 0.6121 - val_loss: 0.7285 - val_accuracy: 0.7604\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.7119 - accuracy: 0.7689 - val_loss: 0.5940 - val_accuracy: 0.8022\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.5598 - accuracy: 0.8178 - val_loss: 0.5881 - val_accuracy: 0.8086\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.4560 - accuracy: 0.8541 - val_loss: 0.5056 - val_accuracy: 0.8324\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.3646 - accuracy: 0.8816 - val_loss: 0.4774 - val_accuracy: 0.8438\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.2853 - accuracy: 0.9077 - val_loss: 0.5297 - val_accuracy: 0.8462\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.2239 - accuracy: 0.9273 - val_loss: 0.5228 - val_accuracy: 0.8470\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.1687 - accuracy: 0.9467 - val_loss: 0.6299 - val_accuracy: 0.8300\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.1343 - accuracy: 0.9571 - val_loss: 0.6283 - val_accuracy: 0.8416\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.1067 - accuracy: 0.9671 - val_loss: 0.5779 - val_accuracy: 0.8528\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0874 - accuracy: 0.9732 - val_loss: 0.6451 - val_accuracy: 0.8352\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0718 - accuracy: 0.9773 - val_loss: 0.7357 - val_accuracy: 0.8400\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0670 - accuracy: 0.9806 - val_loss: 0.6474 - val_accuracy: 0.8556\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0533 - accuracy: 0.9843 - val_loss: 0.6811 - val_accuracy: 0.8478\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0517 - accuracy: 0.9841 - val_loss: 0.8421 - val_accuracy: 0.8312\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0524 - accuracy: 0.9836 - val_loss: 0.7357 - val_accuracy: 0.8468\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0406 - accuracy: 0.9866 - val_loss: 0.7293 - val_accuracy: 0.8448\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0430 - accuracy: 0.9869 - val_loss: 0.7740 - val_accuracy: 0.8352\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0386 - accuracy: 0.9883 - val_loss: 0.7591 - val_accuracy: 0.8412\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0381 - accuracy: 0.9878 - val_loss: 0.8105 - val_accuracy: 0.8470\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0369 - accuracy: 0.9886 - val_loss: 0.7715 - val_accuracy: 0.8518\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0307 - accuracy: 0.9902 - val_loss: 0.8208 - val_accuracy: 0.8480\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0332 - accuracy: 0.9894 - val_loss: 0.7623 - val_accuracy: 0.8518\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0310 - accuracy: 0.9908 - val_loss: 0.7507 - val_accuracy: 0.8448\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0306 - accuracy: 0.9903 - val_loss: 0.8510 - val_accuracy: 0.8332\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0260 - accuracy: 0.9924 - val_loss: 0.7924 - val_accuracy: 0.8514\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0258 - accuracy: 0.9920 - val_loss: 0.8101 - val_accuracy: 0.8462\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0250 - accuracy: 0.9925 - val_loss: 0.8711 - val_accuracy: 0.8446\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0255 - accuracy: 0.9920 - val_loss: 0.8346 - val_accuracy: 0.8428\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0237 - accuracy: 0.9932 - val_loss: 0.7965 - val_accuracy: 0.8422\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0222 - accuracy: 0.9934 - val_loss: 0.7888 - val_accuracy: 0.8540\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0283 - accuracy: 0.9914 - val_loss: 0.7974 - val_accuracy: 0.8476\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 0.8321 - val_accuracy: 0.8602\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.7548 - val_accuracy: 0.8576\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0216 - accuracy: 0.9936 - val_loss: 0.7899 - val_accuracy: 0.8530\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0238 - accuracy: 0.9929 - val_loss: 0.8468 - val_accuracy: 0.8424\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0187 - accuracy: 0.9946 - val_loss: 0.7780 - val_accuracy: 0.8430\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0198 - accuracy: 0.9942 - val_loss: 0.8668 - val_accuracy: 0.8512\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0185 - accuracy: 0.9946 - val_loss: 0.8531 - val_accuracy: 0.8492\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0173 - accuracy: 0.9950 - val_loss: 0.8590 - val_accuracy: 0.8466\n",
            "Epoch 41/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.8923 - val_accuracy: 0.8492\n",
            "Epoch 42/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.0196 - accuracy: 0.9941 - val_loss: 0.8576 - val_accuracy: 0.8432\n",
            "Epoch 43/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.7890 - val_accuracy: 0.8572\n",
            "Epoch 44/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0150 - accuracy: 0.9959 - val_loss: 0.8605 - val_accuracy: 0.8486\n",
            "Epoch 45/100\n",
            "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0161 - accuracy: 0.9954 - val_loss: 0.9145 - val_accuracy: 0.8510\n",
            "Epoch 46/100\n",
            "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.8258 - val_accuracy: 0.8564\n",
            "Epoch 47/100\n",
            "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.8153 - val_accuracy: 0.8524\n",
            "Epoch 48/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.7870 - val_accuracy: 0.8506\n",
            "Epoch 49/100\n",
            "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.9067 - val_accuracy: 0.8418\n",
            "Epoch 50/100\n",
            "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.8105 - val_accuracy: 0.8578\n",
            "Epoch 51/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0144 - accuracy: 0.9960 - val_loss: 0.8213 - val_accuracy: 0.8486\n",
            "Epoch 52/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.9179 - val_accuracy: 0.8554\n",
            "Epoch 53/100\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.8578 - val_accuracy: 0.8552\n",
            "Epoch 54/100\n",
            "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 0.9110 - val_accuracy: 0.8516\n",
            "Epoch 55/100\n",
            "1406/1407 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9954Restoring model weights from the end of the best epoch.\n",
            "1407/1407 [==============================] - 33s 23ms/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.8998 - val_accuracy: 0.8514\n",
            "Epoch 00055: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMnG7XLWDP7r",
        "colab_type": "text"
      },
      "source": [
        "**PREDICTING THE TEST DATAS USING THE VGG19 MODEL:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rklfjEfDAn4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "c12fd10a-45fc-4d52-e66c-216ad13daef2"
      },
      "source": [
        "y_pred_1=model_1.predict(X_test)                         #predicting the x_test datas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.46628857e-04, 6.12606236e-04, 1.32668344e-03, ...,\n",
              "        1.85885897e-03, 2.37092216e-04, 5.10157202e-04],\n",
              "       [1.01280154e-03, 2.25411262e-03, 3.94705130e-05, ...,\n",
              "        4.50803282e-06, 9.96443212e-01, 1.38480624e-04],\n",
              "       [2.16745455e-02, 8.25097226e-03, 8.01353424e-04, ...,\n",
              "        2.28308505e-04, 9.62711632e-01, 3.52672744e-03],\n",
              "       ...,\n",
              "       [1.80890402e-05, 6.04502111e-06, 1.86757738e-04, ...,\n",
              "        2.53281556e-04, 3.32181153e-05, 3.68830661e-05],\n",
              "       [4.06896584e-02, 8.98553133e-01, 1.42469388e-02, ...,\n",
              "        2.70106550e-03, 5.40876063e-03, 1.64408516e-02],\n",
              "       [1.19658525e-05, 7.66907942e-06, 2.83182162e-05, ...,\n",
              "        9.99062598e-01, 3.32028208e-06, 2.86285594e-05]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhHwYRvpDiXz",
        "colab_type": "text"
      },
      "source": [
        "**EVALUATING THE VGG19 MODEL PERFORMANCE ON TEST DATASETS:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEmgw856DAkk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e9cd00f0-0701-477a-d914-9622d8bbb6c6"
      },
      "source": [
        "model.evaluate(X_test,Y_test)                 #evaluating the loss and accuracy of actual and predicted values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 8ms/step - loss: 0.5005 - accuracy: 0.8384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5005126595497131, 0.8384000062942505]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ve2rzjIjMm4K",
        "colab_type": "text"
      },
      "source": [
        "AS the test accuracy of the VGG19 based model is not greater than the previous model, the previously built cnn model is used for new test data predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm1eeR4u0vd_",
        "colab_type": "text"
      },
      "source": [
        "### TO CHECK THE PREDICTIONS OF CNN MODEL:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvyT2eR5y0bC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poI8pKmH0jvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.argmax(y_predicted[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JAQWfz70jrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.matshow(X_test[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INif1Jq2L4Ir",
        "colab_type": "text"
      },
      "source": [
        "**IMPORTING NEW DATASETS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hnbu3csr2kO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "72b9b02d-dce9-47c9-c28d-aa643b2fac50"
      },
      "source": [
        "import pandas as pd                       #loading the new dataset and storing it in a dataframe\n",
        "test_data = pd.read_csv(\"https://raw.githubusercontent.com/dphi-official/Datasets/master/cifar_image_flattened_pixels.csv\")\n",
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>3032</th>\n",
              "      <th>3033</th>\n",
              "      <th>3034</th>\n",
              "      <th>3035</th>\n",
              "      <th>3036</th>\n",
              "      <th>3037</th>\n",
              "      <th>3038</th>\n",
              "      <th>3039</th>\n",
              "      <th>3040</th>\n",
              "      <th>3041</th>\n",
              "      <th>3042</th>\n",
              "      <th>3043</th>\n",
              "      <th>3044</th>\n",
              "      <th>3045</th>\n",
              "      <th>3046</th>\n",
              "      <th>3047</th>\n",
              "      <th>3048</th>\n",
              "      <th>3049</th>\n",
              "      <th>3050</th>\n",
              "      <th>3051</th>\n",
              "      <th>3052</th>\n",
              "      <th>3053</th>\n",
              "      <th>3054</th>\n",
              "      <th>3055</th>\n",
              "      <th>3056</th>\n",
              "      <th>3057</th>\n",
              "      <th>3058</th>\n",
              "      <th>3059</th>\n",
              "      <th>3060</th>\n",
              "      <th>3061</th>\n",
              "      <th>3062</th>\n",
              "      <th>3063</th>\n",
              "      <th>3064</th>\n",
              "      <th>3065</th>\n",
              "      <th>3066</th>\n",
              "      <th>3067</th>\n",
              "      <th>3068</th>\n",
              "      <th>3069</th>\n",
              "      <th>3070</th>\n",
              "      <th>3071</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>98</td>\n",
              "      <td>105</td>\n",
              "      <td>108</td>\n",
              "      <td>92</td>\n",
              "      <td>101</td>\n",
              "      <td>106</td>\n",
              "      <td>91</td>\n",
              "      <td>101</td>\n",
              "      <td>107</td>\n",
              "      <td>93</td>\n",
              "      <td>104</td>\n",
              "      <td>108</td>\n",
              "      <td>89</td>\n",
              "      <td>100</td>\n",
              "      <td>104</td>\n",
              "      <td>88</td>\n",
              "      <td>99</td>\n",
              "      <td>103</td>\n",
              "      <td>90</td>\n",
              "      <td>101</td>\n",
              "      <td>106</td>\n",
              "      <td>95</td>\n",
              "      <td>105</td>\n",
              "      <td>110</td>\n",
              "      <td>99</td>\n",
              "      <td>108</td>\n",
              "      <td>110</td>\n",
              "      <td>109</td>\n",
              "      <td>117</td>\n",
              "      <td>116</td>\n",
              "      <td>119</td>\n",
              "      <td>125</td>\n",
              "      <td>123</td>\n",
              "      <td>125</td>\n",
              "      <td>130</td>\n",
              "      <td>128</td>\n",
              "      <td>134</td>\n",
              "      <td>140</td>\n",
              "      <td>138</td>\n",
              "      <td>140</td>\n",
              "      <td>...</td>\n",
              "      <td>184</td>\n",
              "      <td>178</td>\n",
              "      <td>177</td>\n",
              "      <td>172</td>\n",
              "      <td>190</td>\n",
              "      <td>188</td>\n",
              "      <td>184</td>\n",
              "      <td>220</td>\n",
              "      <td>219</td>\n",
              "      <td>214</td>\n",
              "      <td>195</td>\n",
              "      <td>193</td>\n",
              "      <td>187</td>\n",
              "      <td>176</td>\n",
              "      <td>174</td>\n",
              "      <td>169</td>\n",
              "      <td>175</td>\n",
              "      <td>173</td>\n",
              "      <td>168</td>\n",
              "      <td>192</td>\n",
              "      <td>189</td>\n",
              "      <td>185</td>\n",
              "      <td>185</td>\n",
              "      <td>182</td>\n",
              "      <td>178</td>\n",
              "      <td>168</td>\n",
              "      <td>165</td>\n",
              "      <td>161</td>\n",
              "      <td>178</td>\n",
              "      <td>176</td>\n",
              "      <td>171</td>\n",
              "      <td>183</td>\n",
              "      <td>182</td>\n",
              "      <td>176</td>\n",
              "      <td>175</td>\n",
              "      <td>175</td>\n",
              "      <td>168</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>101</td>\n",
              "      <td>108</td>\n",
              "      <td>101</td>\n",
              "      <td>101</td>\n",
              "      <td>108</td>\n",
              "      <td>101</td>\n",
              "      <td>102</td>\n",
              "      <td>109</td>\n",
              "      <td>102</td>\n",
              "      <td>103</td>\n",
              "      <td>110</td>\n",
              "      <td>103</td>\n",
              "      <td>105</td>\n",
              "      <td>112</td>\n",
              "      <td>104</td>\n",
              "      <td>105</td>\n",
              "      <td>114</td>\n",
              "      <td>109</td>\n",
              "      <td>105</td>\n",
              "      <td>116</td>\n",
              "      <td>112</td>\n",
              "      <td>106</td>\n",
              "      <td>115</td>\n",
              "      <td>110</td>\n",
              "      <td>108</td>\n",
              "      <td>115</td>\n",
              "      <td>108</td>\n",
              "      <td>107</td>\n",
              "      <td>115</td>\n",
              "      <td>107</td>\n",
              "      <td>104</td>\n",
              "      <td>115</td>\n",
              "      <td>106</td>\n",
              "      <td>104</td>\n",
              "      <td>116</td>\n",
              "      <td>108</td>\n",
              "      <td>108</td>\n",
              "      <td>119</td>\n",
              "      <td>115</td>\n",
              "      <td>108</td>\n",
              "      <td>...</td>\n",
              "      <td>149</td>\n",
              "      <td>153</td>\n",
              "      <td>159</td>\n",
              "      <td>164</td>\n",
              "      <td>132</td>\n",
              "      <td>140</td>\n",
              "      <td>142</td>\n",
              "      <td>134</td>\n",
              "      <td>144</td>\n",
              "      <td>145</td>\n",
              "      <td>112</td>\n",
              "      <td>119</td>\n",
              "      <td>118</td>\n",
              "      <td>108</td>\n",
              "      <td>115</td>\n",
              "      <td>111</td>\n",
              "      <td>114</td>\n",
              "      <td>124</td>\n",
              "      <td>122</td>\n",
              "      <td>106</td>\n",
              "      <td>118</td>\n",
              "      <td>116</td>\n",
              "      <td>101</td>\n",
              "      <td>113</td>\n",
              "      <td>108</td>\n",
              "      <td>100</td>\n",
              "      <td>111</td>\n",
              "      <td>102</td>\n",
              "      <td>99</td>\n",
              "      <td>110</td>\n",
              "      <td>103</td>\n",
              "      <td>100</td>\n",
              "      <td>109</td>\n",
              "      <td>104</td>\n",
              "      <td>100</td>\n",
              "      <td>109</td>\n",
              "      <td>103</td>\n",
              "      <td>100</td>\n",
              "      <td>109</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>85</td>\n",
              "      <td>115</td>\n",
              "      <td>27</td>\n",
              "      <td>63</td>\n",
              "      <td>90</td>\n",
              "      <td>25</td>\n",
              "      <td>37</td>\n",
              "      <td>66</td>\n",
              "      <td>15</td>\n",
              "      <td>69</td>\n",
              "      <td>93</td>\n",
              "      <td>49</td>\n",
              "      <td>40</td>\n",
              "      <td>52</td>\n",
              "      <td>36</td>\n",
              "      <td>18</td>\n",
              "      <td>24</td>\n",
              "      <td>18</td>\n",
              "      <td>31</td>\n",
              "      <td>38</td>\n",
              "      <td>27</td>\n",
              "      <td>79</td>\n",
              "      <td>91</td>\n",
              "      <td>61</td>\n",
              "      <td>104</td>\n",
              "      <td>117</td>\n",
              "      <td>78</td>\n",
              "      <td>72</td>\n",
              "      <td>84</td>\n",
              "      <td>52</td>\n",
              "      <td>68</td>\n",
              "      <td>79</td>\n",
              "      <td>52</td>\n",
              "      <td>122</td>\n",
              "      <td>131</td>\n",
              "      <td>85</td>\n",
              "      <td>104</td>\n",
              "      <td>113</td>\n",
              "      <td>67</td>\n",
              "      <td>77</td>\n",
              "      <td>...</td>\n",
              "      <td>139</td>\n",
              "      <td>174</td>\n",
              "      <td>188</td>\n",
              "      <td>139</td>\n",
              "      <td>182</td>\n",
              "      <td>198</td>\n",
              "      <td>150</td>\n",
              "      <td>179</td>\n",
              "      <td>194</td>\n",
              "      <td>147</td>\n",
              "      <td>175</td>\n",
              "      <td>186</td>\n",
              "      <td>142</td>\n",
              "      <td>187</td>\n",
              "      <td>195</td>\n",
              "      <td>158</td>\n",
              "      <td>176</td>\n",
              "      <td>191</td>\n",
              "      <td>142</td>\n",
              "      <td>169</td>\n",
              "      <td>190</td>\n",
              "      <td>132</td>\n",
              "      <td>177</td>\n",
              "      <td>193</td>\n",
              "      <td>144</td>\n",
              "      <td>180</td>\n",
              "      <td>189</td>\n",
              "      <td>147</td>\n",
              "      <td>175</td>\n",
              "      <td>190</td>\n",
              "      <td>141</td>\n",
              "      <td>172</td>\n",
              "      <td>193</td>\n",
              "      <td>136</td>\n",
              "      <td>173</td>\n",
              "      <td>192</td>\n",
              "      <td>138</td>\n",
              "      <td>179</td>\n",
              "      <td>192</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>213</td>\n",
              "      <td>213</td>\n",
              "      <td>214</td>\n",
              "      <td>215</td>\n",
              "      <td>214</td>\n",
              "      <td>218</td>\n",
              "      <td>220</td>\n",
              "      <td>218</td>\n",
              "      <td>226</td>\n",
              "      <td>223</td>\n",
              "      <td>221</td>\n",
              "      <td>233</td>\n",
              "      <td>226</td>\n",
              "      <td>225</td>\n",
              "      <td>231</td>\n",
              "      <td>225</td>\n",
              "      <td>226</td>\n",
              "      <td>223</td>\n",
              "      <td>223</td>\n",
              "      <td>223</td>\n",
              "      <td>223</td>\n",
              "      <td>227</td>\n",
              "      <td>226</td>\n",
              "      <td>231</td>\n",
              "      <td>229</td>\n",
              "      <td>228</td>\n",
              "      <td>236</td>\n",
              "      <td>229</td>\n",
              "      <td>228</td>\n",
              "      <td>236</td>\n",
              "      <td>230</td>\n",
              "      <td>229</td>\n",
              "      <td>236</td>\n",
              "      <td>228</td>\n",
              "      <td>227</td>\n",
              "      <td>235</td>\n",
              "      <td>227</td>\n",
              "      <td>226</td>\n",
              "      <td>234</td>\n",
              "      <td>225</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>111</td>\n",
              "      <td>41</td>\n",
              "      <td>28</td>\n",
              "      <td>111</td>\n",
              "      <td>63</td>\n",
              "      <td>60</td>\n",
              "      <td>120</td>\n",
              "      <td>92</td>\n",
              "      <td>98</td>\n",
              "      <td>138</td>\n",
              "      <td>117</td>\n",
              "      <td>129</td>\n",
              "      <td>153</td>\n",
              "      <td>140</td>\n",
              "      <td>158</td>\n",
              "      <td>172</td>\n",
              "      <td>161</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>174</td>\n",
              "      <td>205</td>\n",
              "      <td>195</td>\n",
              "      <td>182</td>\n",
              "      <td>212</td>\n",
              "      <td>199</td>\n",
              "      <td>185</td>\n",
              "      <td>216</td>\n",
              "      <td>197</td>\n",
              "      <td>186</td>\n",
              "      <td>216</td>\n",
              "      <td>193</td>\n",
              "      <td>194</td>\n",
              "      <td>209</td>\n",
              "      <td>201</td>\n",
              "      <td>204</td>\n",
              "      <td>216</td>\n",
              "      <td>203</td>\n",
              "      <td>201</td>\n",
              "      <td>237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41</td>\n",
              "      <td>74</td>\n",
              "      <td>144</td>\n",
              "      <td>41</td>\n",
              "      <td>75</td>\n",
              "      <td>139</td>\n",
              "      <td>41</td>\n",
              "      <td>75</td>\n",
              "      <td>139</td>\n",
              "      <td>41</td>\n",
              "      <td>74</td>\n",
              "      <td>144</td>\n",
              "      <td>39</td>\n",
              "      <td>76</td>\n",
              "      <td>140</td>\n",
              "      <td>37</td>\n",
              "      <td>79</td>\n",
              "      <td>130</td>\n",
              "      <td>38</td>\n",
              "      <td>77</td>\n",
              "      <td>135</td>\n",
              "      <td>40</td>\n",
              "      <td>75</td>\n",
              "      <td>142</td>\n",
              "      <td>43</td>\n",
              "      <td>72</td>\n",
              "      <td>145</td>\n",
              "      <td>47</td>\n",
              "      <td>71</td>\n",
              "      <td>146</td>\n",
              "      <td>47</td>\n",
              "      <td>73</td>\n",
              "      <td>140</td>\n",
              "      <td>43</td>\n",
              "      <td>75</td>\n",
              "      <td>140</td>\n",
              "      <td>39</td>\n",
              "      <td>77</td>\n",
              "      <td>143</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>149</td>\n",
              "      <td>42</td>\n",
              "      <td>71</td>\n",
              "      <td>135</td>\n",
              "      <td>43</td>\n",
              "      <td>72</td>\n",
              "      <td>125</td>\n",
              "      <td>42</td>\n",
              "      <td>72</td>\n",
              "      <td>122</td>\n",
              "      <td>51</td>\n",
              "      <td>72</td>\n",
              "      <td>117</td>\n",
              "      <td>64</td>\n",
              "      <td>70</td>\n",
              "      <td>109</td>\n",
              "      <td>65</td>\n",
              "      <td>72</td>\n",
              "      <td>99</td>\n",
              "      <td>53</td>\n",
              "      <td>76</td>\n",
              "      <td>113</td>\n",
              "      <td>35</td>\n",
              "      <td>75</td>\n",
              "      <td>136</td>\n",
              "      <td>30</td>\n",
              "      <td>81</td>\n",
              "      <td>140</td>\n",
              "      <td>34</td>\n",
              "      <td>79</td>\n",
              "      <td>133</td>\n",
              "      <td>41</td>\n",
              "      <td>77</td>\n",
              "      <td>130</td>\n",
              "      <td>44</td>\n",
              "      <td>75</td>\n",
              "      <td>133</td>\n",
              "      <td>42</td>\n",
              "      <td>73</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  3072 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2    3    4    5    6  ...  3065  3066  3067  3068  3069  3070  3071\n",
              "0   98  105  108   92  101  106   91  ...   176   175   175   168   181   181   175\n",
              "1  101  108  101  101  108  101  102  ...   104   100   109   103   100   109   102\n",
              "2   85  115   27   63   90   25   37  ...   136   173   192   138   179   192   149\n",
              "3  213  213  214  215  214  218  220  ...   209   201   204   216   203   201   237\n",
              "4   41   74  144   41   75  139   41  ...   130    44    75   133    42    73   144\n",
              "\n",
              "[5 rows x 3072 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRvpRyoHMAa4",
        "colab_type": "text"
      },
      "source": [
        "**PREPROCESSING THE NEW DATASETS:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgPT9a-of13o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data1=np.array(test_data)                   #converting the dataframe into array\n",
        "test_data1=test_data1.reshape(2000,32,32,3)      #reshaping the array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trCEOktUr2hv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data1 = test_data1.astype('float32')/ 255   #normalizing the new dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUnk8N1lsd3H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6564500-fac2-4950-c7d0-1ee25a52ff65"
      },
      "source": [
        "test_data1.shape                                 #printing the shape of new dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNUI43gpMHAD",
        "colab_type": "text"
      },
      "source": [
        "**MAKING PREDICTIONS ON NEW DATASETS WITH BUILT MODEL:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCCuo69XtK6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions=model.predict(test_data1)   #making predictions on the new dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrMOtAGPhvK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=np.argmax(predictions,axis=1)      #as softmax function produces outputs of 10 different classes, argmax is used to return the maximum value of that 10 outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLT0zqPKMR9u",
        "colab_type": "text"
      },
      "source": [
        "**STORING THE PREDICTION RESULTS:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOLLsRmRiM6M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "outputId": "e94e853d-feb5-418c-f417-11ff37e16ff4"
      },
      "source": [
        "res = pd.DataFrame(data)            #converting the array into dataframe\n",
        "res.index = test_data.index         #keeping the index position of res as a test_data variable\n",
        "res.columns = [\"predictions\"]       #keeping the column position of res as a predictions variable\n",
        "\n",
        "# To download the csv file locally\n",
        "from google.colab import files           #importing files library\n",
        "res.to_csv('prediction_results.csv')     #converting the res dataframe into an prediction_results csv file\n",
        "files.download('prediction_results.csv') #down;oading the csv file\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_12ebae6b-d576-4681-aa0a-dda59a60b09a\", \"prediction_results.csv\", 12903)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}